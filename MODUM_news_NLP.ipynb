{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MODUM_news_NLP.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeGbcWQCDeVL",
        "colab_type": "code",
        "outputId": "ef58fdae-8655-472c-930f-fabb2e2d2714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "pip install aylien-news-api\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting aylien-news-api\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/32/27c691fe9abaa07d4befc9f4ba051ed03baaf1fc5a4f3d87529cbca3f372/aylien_news_api-3.0.0-py3-none-any.whl (114kB)\n",
            "\r\u001b[K     |██▉                             | 10kB 28.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 20kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 30kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 40kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 61kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 71kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 81kB 10.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 92kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 102kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 112kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from aylien-news-api) (2020.4.5.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from aylien-news-api) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from aylien-news-api) (2.8.1)\n",
            "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.6/dist-packages (from aylien-news-api) (1.24.3)\n",
            "Installing collected packages: aylien-news-api\n",
            "Successfully installed aylien-news-api-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyZpZ1gklFSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "787e755f-7593-468e-fa28-342f9d41bc43"
      },
      "source": [
        "pip install --upgrade aylien-apiclient\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting aylien-apiclient\n",
            "  Downloading https://files.pythonhosted.org/packages/f8/2e/f901d788b248afb61e5f4f5a1439df0a858aaeaea30bab425cd1e1dc685b/aylien-apiclient-0.7.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: httplib2>=0.9 in /usr/local/lib/python3.6/dist-packages (from aylien-apiclient) (0.17.3)\n",
            "Building wheels for collected packages: aylien-apiclient\n",
            "  Building wheel for aylien-apiclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aylien-apiclient: filename=aylien_apiclient-0.7.0-cp36-none-any.whl size=9100 sha256=e94a8f71159a909e07dbc99009ba0a4d820e9cb877abdb511d3a58e365909a09\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/72/c6/b11d6bca9428ae3841ea52cc60924e8d916c00c2a10fc6fbea\n",
            "Successfully built aylien-apiclient\n",
            "Installing collected packages: aylien-apiclient\n",
            "Successfully installed aylien-apiclient-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_VTBYaQ7r3U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36bdc072-86b9-4867-e355-ae3bb26c3f13"
      },
      "source": [
        "pip install numpy\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bakqvwIh09LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eu = ['Austria','Belgium',\t'Latvia',\n",
        "'Bulgaria',\t'Lithuania',\n",
        "'Croatia',\t'Luxembourg',\n",
        "'Cyprus',\t'Malta',\n",
        "'Czechia',\t'Netherlands',\n",
        "'Denmark',\t'Poland',\n",
        "'Estonia',\t'Portugal',\n",
        "'Finland',\t'Romania',\n",
        "'France',\t'Slovakia'\n",
        ",'Germany'\t,'Slovenia',\n",
        "'Greece',\t'Spain',\n",
        "'Hungary',\t'Sweden',\n",
        "'Ireland'\t, 'Italy'\n",
        "]\n",
        "#eu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ziZnQ5GReAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import aylien_news_api\n",
        "from aylien_news_api.rest import ApiException\n",
        "from pprint import pprint as pp\n",
        "from aylienapiclient import textapi\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "## Configure your connection to the text API for the entitty analysis\n",
        "client = textapi.Client(\"ff8582ad\", \"dcd4163e8b5f804371edce48e5d2ffbc\")\n",
        "\n",
        "\n",
        "## Configure your connection to the news API\n",
        "configuration = aylien_news_api.Configuration()\n",
        "configuration.api_key['X-AYLIEN-NewsAPI-Application-ID'] = 'c9e7d89a'\n",
        "configuration.api_key['X-AYLIEN-NewsAPI-Application-Key'] = '91870c11ec400bec0a2fdf0d3f32cc99'\n",
        "configuration.host = \"https://api.aylien.com/news\"\n",
        "api_instance = aylien_news_api.DefaultApi(aylien_news_api.ApiClient(configuration))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3G6PhlWpmS2",
        "colab_type": "code",
        "outputId": "482dd27a-c7de-4585-a24a-9f250aee0509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#example to retrieve location from the textapi\n",
        "text = \"ACME corp was founded by John Smith in Chicago.\"\n",
        "entities = client.Entities({\"text\": text})\n",
        "print(entities['entities']['location'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Chicago']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEY4wZDivENo",
        "colab_type": "code",
        "outputId": "d5f5171b-7d5e-4d05-d168-ef16041a1b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "text=\"Corona authorities Eindhoven beds happy excited great news victims Garissa virus residents case GARISSA health hospital Dagane spread government governor deputy deaths hand washing hygiene referral hospital quarantine department Garissa County\"\n",
        "# 'entities': [{'mentions': [{'offset': 133, 'confidence': 1.0, 'text': 'hand washing', 'sentiment': {'polarity': 'negative', 'confidence': 0.5}}], 'overall_sentiment': {'polarity': 'negative', 'confidence': 0.5}, 'type': 'Organization', 'links': [{'uri': 'http://dbpedia.org/resource/Hand_washing', 'provider': 'dbpedia', 'types': ['http://dbpedia.org/ontology/Act', 'http://dbpedia.org/ontology/Band'], 'confidence': 0.01}]}, {'mentions': [{'offset': 183, 'confidence': 1.0, 'text': 'department', 'sentiment': {'polarity': 'neutral', 'confidence': 0.46}}], 'overall_sentiment': {'polarity': 'neutral', 'confidence': 0.46}, 'type': 'Organization', 'links': [{'uri': 'http://dbpedia.org/resource/Departments_of_France', 'provider': 'dbpedia', 'types': ['http://dbpedia.org/ontology/Levels', 'http://dbpedia.org/ontology/SportsLeague'], 'confidence': 4.25}]}, {'mentions': [{'offset': 32, 'confidence': 0.98, 'text': 'Garissa', 'sentiment': {'polarity': 'negative', 'confidence': 0.6}}], 'overall_sentiment': {'polarity': 'negative', 'confidence': 0.6}, 'type': 'Location', 'links': [{'uri': 'http://dbpedia.org/resource/Garissa', 'provider': 'dbpedia', 'types': ['http://dbpedia.org/ontology/Location', 'http://dbpedia.org/ontology/PopulatedPlace', 'http://schema.org/Place', 'http://dbpedia.org/ontology/Settlement', 'http://dbpedia.org/ontology/Town', 'http://dbpedia.org/ontology/Place', 'http://dbpedia.org/ontology/Capital'], 'confidence': 0.01}]}, {'mentions': [{'offset': 85, 'confidence': 1.0, 'text': 'Dagane', 'sentiment': {'polarity': 'negative', 'confidence': 0.55}}], 'overall_sentiment': {'polarity': 'negative', 'confidence': 0.55}, 'type': 'Person', 'links': []}, {'mentions': [{'offset': 194, 'confidence': 1.0, 'text': 'Garissa County', 'sentiment': {'polarity': 'neutral', 'confidence': 0.52}}], 'overall_sentiment': {'polarity': 'neutral', 'confidence': 0.52}, 'type': 'Person', 'links': []}, {'mentions': [{'offset': 0, 'confidence': 0.7, 'text': 'Corona', 'sentiment': {'polarity': 'neutral', 'confidence': 0.47}}], 'overall_sentiment': {'polarity': 'neutral', 'confidence': 0.47}, 'type': 'Location', 'links': [{'uri': 'http://dbpedia.org/resource/Corona,_California', 'provider': 'dbpedia', 'types': ['http://dbpedia.org/ontology/Location', 'http://dbpedia.org/ontology/PopulatedPlace', 'http://schema.org/Place', 'http://dbpedia.org/ontology/Settlement', 'http://dbpedia.org/ontology/City', 'http://dbpedia.org/ontology/Place', 'http://schema.org/City'], 'confidence': 0.02}]}, {'mentions': [{'offset': 194, 'confidence': 1.0, 'text': 'Garissa County', 'sentiment': {'polarity': 'neutral', 'confidence': 0.52}}], 'overall_sentiment': {'polarity': 'neutral', 'confidence': 0.52}, 'type': 'Location', 'links': [{'uri': 'http://dbpedia.org/resource/Garissa_County', 'provider': 'dbpedia', 'types': ['http://dbpedia.org/ontology/AdministrativeRegion', 'http://dbpedia.org/ontology/Location', 'http://dbpedia.org/ontology/PopulatedPlace', 'http://schema.org/Place', 'http://dbpedia.org/ontology/Settlement', 'http://dbpedia.org/ontology/County', 'http://dbpedia.org/ontology/Place'], 'confidence': 0.01}]}, {'mentions': [{'offset': 76, 'confidence': 1.0, 'text': 'hospital', 'sentiment': {'polarity': 'negative', 'confidence': 0.65}}], 'overall_sentiment': {'polarity': 'negative', 'confidence': 0.65}, 'type': 'Organization', 'links': [{'uri': 'http://dbpedia.org/resource/Hospital', 'provider': 'dbpedia', 'types': ['http://dbpedia.org/ontology/Institution', 'http://dbpedia.org/ontology/University', 'http://dbpedia.org/ontology/PersonFunction'], 'confidence': 0.69}]}, {'mentions': [{'offset': 194, 'confidence': 1.0, 'text': 'Garissa', 'sentiment': {'polarity': 'negative', 'confidence': 0.46}}, {'offset': 32, 'confidence': 1.0, 'text': 'Garissa', 'sentiment': {'polarity': 'negative', 'confidence': 0.6}}], 'overall_sentiment': {'polarity': 'negative', 'confidence': 0.6}, 'type': 'Person', 'links': []}, {'mentions': [{'offset': 61, 'confidence': 0.98, 'text': 'GARISSA', 'sentiment': {'polarity': 'negative', 'confidence': 0.56}}], 'overall_sentiment': {'polarity': 'negative', 'confidence': 0.56}, 'type': 'Location', 'links': [{'uri': 'http://dbpedia.org/resource/Garissa', 'provider': 'dbpedia', 'types': ['http://dbpedia.org/ontology/Location', 'http://dbpedia.org/ontology/PopulatedPlace', 'http://schema.org/Place', 'http://dbpedia.org/ontology/Settlement', 'http://dbpedia.org/ontology/Town', 'http://dbpedia.org/ontology/Place', 'http://dbpedia.org/ontology/Capital'], 'confidence': 0.01}]}, {'mentions': [{'offset': 154, 'confidence': 1.0, 'text': 'referral hospital', 'sentiment': {'polarity': 'neutral', 'confidence': 0.48}}], 'overall_sentiment': {'polarity': 'neutral', 'confidence': 0.48}, 'type': 'Location', 'links': [{'uri': 'http://dbpedia.org/resource/Tertiary_referral_hospital', 'provider': 'dbpedia', 'types': ['http://dbpedia.org/ontology/Hospital'], 'confidence': 0.0}]}]}\n",
        "elsa = client.Elsa({'text': text})\n",
        "print(elsa['entities'][0])\n",
        "print(elsa['entities'][0]['type'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'mentions': [{'offset': 19, 'confidence': 1.0, 'text': 'Eindhoven', 'sentiment': {'polarity': 'positive', 'confidence': 0.47}}], 'overall_sentiment': {'polarity': 'positive', 'confidence': 0.47}, 'type': 'Location', 'links': [{'uri': 'http://dbpedia.org/resource/Eindhoven', 'provider': 'dbpedia', 'types': ['http://schema.org/City', 'http://dbpedia.org/ontology/Place', 'http://schema.org/Place', 'http://dbpedia.org/ontology/City', 'http://dbpedia.org/ontology/Settlement', 'http://dbpedia.org/ontology/Location', 'http://dbpedia.org/ontology/PopulatedPlace', 'http://dbpedia.org/ontology/Municipality'], 'confidence': 0.13}]}\n",
            "Location\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF8UIHanmN4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## List our parameters as search operators\n",
        "opts= {\n",
        "    'title': '\"corona\" OR \"measures\" OR \"increase\" OR \"ICU\" OR \"infected\"',\n",
        "    'body': '\"corona\" OR \"measures\" OR \"increase\" OR \"ICU\" OR \"infected\" OR \"satisfied\" OR \"people\" or \"behavior\"',\n",
        "    'language': ['en'],\n",
        "    'published_at_start': 'NOW-3MONTHS',\n",
        "    'published_at_end': 'NOW',\n",
        "    'per_page': 100,\n",
        "    'sort_by': 'relevance',\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxG6zGqWmGYN",
        "colab_type": "code",
        "outputId": "c5342f1c-b4a0-4ee1-c3ee-e50c98924c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#listing non paginated data: the first 100 news related\n",
        "#cluster [109770755]\n",
        "keywords = []\n",
        "try:\n",
        "    ## Make a call to the Stories endpoint for stories that meet the criteria of the search operators\n",
        "    api_response = api_instance.list_stories(**opts)\n",
        "    ## Print the returned story\n",
        "    \n",
        "    i=0\n",
        "    for story in api_response.stories:\n",
        "      for keyword in story.keywords:\n",
        "        keywords.append(keyword)\n",
        "      print(keywords)\n",
        "      keywords=[]\n",
        "\n",
        "except ApiException as e:\n",
        "    print('Exception when calling DefaultApi->list_stories: %s\\n' % e)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Corona', 'authorities', 'beds', 'victims', 'Garissa', 'virus', 'residents', 'case', 'GARISSA', 'health', 'hospital', 'Dagane', 'spread', 'government', 'governor', 'deputy', 'deaths', 'hand washing', 'hygiene', 'referral hospital', 'quarantine', 'department', 'Garissa County']\n",
            "['infected', 'patients', 'repair', 'virus', 'Corona', 'renovation', 'Estblishment', 'work', 'Address', 'Tender', '031', 'Purta', 'Floor', 'Bhaban', 'Authority', 'Shahjahan', 'info', 'Bangladesh', 'Phone', 'Rahmatgonj', 'Contact', 'Public Works Department', 'ward']\n",
            "['Corona', 'ventilators', 'Chattogram', 'Hospital', 'facilities', 'Health', 'General', 'news', 'government', '10-bed', 'Ministry', 'Rabbi', 'Welfare', 'Family', 'General Hospital', 'corona', 'DHAKA', 'surgeon', 'hospital', 'coronavirus', 'Bangladesh', 'Sheikh']\n",
            "['Corona', 'ventilators', 'CHATTOGRAM', 'Hospital', 'facilities', 'General', 'Health', '10-bed', 'government', 'Rabbi', 'Welfare', 'patients', 'Family', 'General Hospital', 'corona', 'surgeon', 'hospital', 'coronavirus', 'Sheikh']\n",
            "['Virus', 'Corona', 'Awareness', 'Inspection', 'Increase', 'corona virus', 'health', 'Immigration Post', 'measures', 'virus', 'Ministry', 'Yang', 'common', 'corona', 'immigration', 'posts', 'Haji', 'people', 'diseases', 'Sultan', 'country', 'fever', 'infection', 'Yang Di-Pertuan', 'vaccine', 'Yang Berhormat', 'pneumonia', 'SARS', 'symptom', 'Brunei Darussalam', 'RTB', 'viruses', 'sore throat', 'body temperature']\n",
            "['infected', 'Corona', 'patients', 'hours', 'Corona Virus', 'Content', 'Virus', 'hospitals', 'Lanka', 'requirement', 'article', 'respect', 'persons', 'query', 'News', 'contact', 'Hiru', 'permission', 'Covid-19', 'Sri Lanka']\n",
            "['Corona', 'on-call', 'patients', 'nurses', 'sick', 'experience', 'Doctors', 'surreal', 'layers', 'people', 'friend', 'unusual', 'system', 'justification', 'terrible', 'hours', 'chance', 'night', 'internist', 'catharsis', 'confidentiality', 'immune system', 'visor', 'The nurses', 'toilet', 'fog', 'cardiac arrest', 'apologize', 'airlock', 'sleep', 'corona', 'screw', 'social media', 'guard', 'hospital', 'endangered', 'ER', 'Covid', 'bradycardic']\n",
            "['deaths', 'Corona', 'infected', 'people', 'virus', 'number', 'Iran', 'Corona virus', 'Health', 'Jahanpur', 'press', 'conference', 'Kyanosh', 'Ministry', 'today', 'increase', 'Spokesman', 'Sunday', 'Baghdad', 'epidemic', 'Qom']\n",
            "['Corona', 'Mosul', 'virus', 'persons', 'Corona virus', 'infected', 'Directorate', 'NINA', 'Nineveh', 'Health', 'News', 'Iraqi', 'Agency', 'Al-Taie', 'National', 'channel', 'Falah', 'Al-Iraqiya', 'Coruna', 'people', 'laboratory', 'infection', 'Nineveh Governorate']\n",
            "['institute', 'urology', 'centre', 'Corona', 'kidney', 'patients', 'corona', 'virus', 'transplant', 'people', 'facility', 'emergency', 'notice', 'Randawa', 'week', 'Mehmood', 'single', 'preparation', 'level', 'Khalid', 'Medical', 'kidney transplant', 'corona virus', 'Rawalpindi']\n",
            "['Corona', 'virus', 'northern', 'family', 'Iraqi', 'Italy', 'Iraqi Embassy', 'Embassy', 'infected', 'statement', 'stable', 'Rome', 'people', 'health', 'NINA', 'Baghdad']\n",
            "['Corona', 'Measures', 'People', 'Norway', 'Telenor’s mobile', 'social distance', 'Telenor’s data', 'people', 'measures', 'mobile', 'Telenor', 'social', 'regular', 'market', 'distance', 'government', 'data', 'week', 'health', 'strict', 'peacetime', 'mobile operator', 'manager', 'big data', 'NRK', 'Norwegian', 'lockdown', 'virus']\n",
            "['Virus', 'Corona', 'Suspected', 'Palestinian', 'Infected', 'Palestinian prisoners', 'Prisoners', 'Israeli', 'Committee', 'Coronavirus', 'jail', 'authorities', 'quarantine', 'statement', 'human', 'rights', 'masks', 'groups', 'Chief', 'Abdelnasser', 'Ferwana', 'Arab', 'Israeli parliament', 'human rights', 'virus', 'IPS']\n",
            "['Rajasthan', 'patients', 'total', 'infected', 'figure', 'corona', 'corona-infected people', 'infected people', 'people', 'Jaipur', 'corona-infected', 'Topkhana', 'Sodala', 'Ramnagar', 'Hazuri', 'Hasanpura', 'lockdown', 'Tuesday', 'Banipark', 'Jodhpur', 'Bharatpur', 'Ajmer', 'Kota', 'Tonk']\n",
            "['lists', 'Corona', 'myths', 'measures', 'AIIMS', 'medical mask', 'infected person', 'Medical', 'person', 'disease', 'Content', 'mask', 'coughs', 'infection', 'hands', 'contacts', 'symptoms', 'cases', 'Virus', 'distance', 'mouth', 'sneezing', 'handwashing', 'alcohol', 'healthcare', 'handkerchief', 'hygiene', 'infectious disease', 'fever', 'tissue paper', 'India', 'Common', 'cough', 'meat', 'eggs', 'air', 'hand sanitizer', 'symptomatic treatment', 'New Delhi', 'viral infection', 'hospital', 'chicken', 'Coronavirus', 'body temperature']\n",
            "['persons', 'infected', 'Delhi', 'Corona', 'Mumbai', 'number', 'increase', 'New Delhi', 'Corona Virus', 'Content', 'Virus', 'milk', 'individuals', 'requirement', 'article', 'respect', 'query', 'News', 'contact', 'Hiru', 'permission', 'clip', 'India', 'bowser', 'epicenter', 'Sri Lanka', 'Maharashtra', 'Taj Mahal', 'virus', 'Agra']\n",
            "['spectre', 'Dispur', 'virus', 'control', 'Corona', 'measures', 'corona virus', 'Chief Minister', 'corona', 'health', 'Sunday', 'people', 'case', 'Chief', 'India', 'Minister', 'COVID-19', 'official', 'Assam', 'funds', 'care', 'infection', 'Asian', 'Narendra Modi', 'Delhi', 'Principal Secretary', 'hygiene', 'Karnataka', 'Haryana', 'department', 'Chief Secretary', 'Kerala', 'Maharashtra', 'Sarbananda Sonowal', 'preventive care', 'fallout', 'SAARC', 'Prime Minister', 'pandemic', 'Uttar Pradesh', 'prayer', 'swimming']\n",
            "['doctor', 'Infected', 'corona', 'resident', 'virus', 'corona virus', 'Hospital', 'quarantine', 'NINA', 'Wasit', 'General', 'Al-Zahra', 'Al-Kut', 'Al-Tai', 'Haider', 'National', 'Iraqi', 'Directorate', 'News', 'person', 'personnel', 'General Hospital', 'infection', 'Wasit Governorate', 'Corona', 'hospital', 'Kut']\n",
            "['Corona', 'infected', 'persons', 'virus', 'Directorate', 'hours', 'province', 'Health', 'free', 'Diyala', 'epidemic', 'Diyala Health', 'Fares Al-Azzawi', 'National Iraqi', 'people', 'NINA', 'Al-Azzawi', 'Iraqi', 'Fares', 'National', 'correspondent', 'measures', 'News', 'laboratory', 'curfew', 'Baquba', 'infection', 'Diyala Governorate', 'department', 'public health']\n",
            "['people', 'spread', 'Korea', 'South', 'Corona', 'South Korea', 'actual malicious', 'infection', 'program', 'malicious', 'malware', 'actual', 'control', 'items', 'variant', 'Security', 'status', 'window', 'threat', 'file', 'screen', 'PC', 'malicious program', 'Malware', 'remote control', 'vaccine', 'executable program', 'corona', 'EXE', 'private IP address']\n",
            "['cases', 'Saudi', 'corona', 'Arabia', 'increase', 'Sharp', 'total', 'Saudi Arabia', 'ministry’s Contact', 'infected people', 'Ministry', 'contact', 'Health', 'people', 'infections', 'public', 'number', 'Sunday', 'Abdel', 'society', 'RIYADH', 'Riyadh', 'Makkah', 'Mecca', 'Dammam', 'Khobar', 'Al-Ahsa', 'Al-Qatif', 'Turkish', 'pandemic', 'Saudi Gazette', 'coronavirus', 'Dhahran']\n",
            "['case', 'Suspected', 'Corona-infected', 'Isfahan', 'Corona Virus', 'Arash Najimi', 'Farabi Hospital', 'patient', 'Tehran', 'Virus', 'Arash', 'IRNA', 'Hospital', 'Corona', 'Farabi', 'Najimi', 'Laboratory', 'Sunday', 'Virology', 'University', 'airport', 'Isfahan University', 'news agency', 'Iran', 'fever', 'cough', 'Chinese', 'virus', 'province']\n",
            "['Infected', 'Corona', 'Person', 'Police', 'Kohat Police', 'Infected Person', 'infected person', 'infected persons', 'KOHAT', 'area', 'Commissioner', 'Ibrahim', 'Assistant', 'Additional', 'Khan', 'Rehman', '05th', 'April', 'seconds', 'Gumbat', '@FahadShabbir', 'Ibrahim Khan', 'Shapur', 'Pakistan', 'infection', 'Assistant Commissioner', 'Kohat', 'coronavirus']\n",
            "['zone', 'corona', 'Doctors', 'battle', 'Doctor Mohan', 'Doctor Nath', 'COVID wards', 'patient', 'Covid', 'Mohan', 'duty', 'disease', 'infectivity', 'ward', 'Nath', 'situation', 'IANS', 'hours', 'PPE', 'Delhi', 'AIIMS Delhi', 'The shield', 'The hours', 'contagious disease', 'infection', 'trauma centre', 'Indian government', 'quarantine', 'sweat', 'aerosols', 'viral load', 'thrice', 'The doctor', 'AIIMS', 'India', 'Anaesthesiology', 'Kerala', 'tense', 'armed forces', 'war', 'Wuhan', 'China', 'critical care', 'New Delhi', 'virus', 'hospital', 'pandemic', 'stress', 'COVID-19', 'novel coronavirus', 'COVID', 'covid', 'coronavirus', 'wards', 'Ajay']\n",
            "['infected', 'Saturday', 'patients', 'Rajasthan', 'corona', 'infection', 'people', 'Jaipur', 'Coronavirus', 'Today', 'districts', 'number', 'Ajmer', 'Kota', 'Jodhpur', 'cases', 'Banswara', 'Nagaur', 'Bhilwara', 'Bharatpur', 'Jaisalmer', 'virus', 'district', 'coronavirus']\n",
            "['Virus', 'Corona', 'Lanka', 'persons', 'number', 'increase', 'Sri Lanka', 'Content', 'requirement', 'article', 'respect', 'query', 'News', 'contact', 'Hiru', 'permission', 'Digital', 'Editor', 'hospitals', 'Unit', 'medical', 'treatment']\n",
            "['Khasi', 'Hills', 'West', 'machine', 'corona', 'centre', 'beds', 'corona centre', 'Corona Centre', 'Centre', 'equipments', 'Corona', 'April', 'furniture', 'NONGSTOIN', 'ready', 'COVID-19', 'monitors', 'District', 'media', 'Administration', 'DM&HO', 'Bareh', 'DM', 'almirah', 'lockdown']\n",
            "['India', 'cases', 'lockdown', 'Corona', 'increase', 'corona', 'time', 'sources', 'number', 'government', 'patients', 'week', 'fight', 'guidelines', 'month', 'assessment', 'answer', 'Ministry', 'internal', 'lock-down', 'Home Ministry', 'Coronavirus', 'peak']\n",
            "['corona', 'Mardan', 'virus', 'PTI', 'corona virus', 'people', 'coronavirus', 'Manga', 'disease', 'infection', 'positive', 'touch', 'time', 'area', 'distressed', 'Abdul', 'Afridi', 'Salam', 'treatment', 'quarantine', 'Pakh-tukhwa', 'blood test', 'Pakistan Tehreek-e-Insaf', 'repentance']\n",
            "['infected', 'patients', 'Rajasthan', 'corona', 'today', 'number', 'people', 'infected people', 'positive patients', 'positive', 'Jodhpur', 'Jaipur', 'Wednesday', 'arrival', 'Banswara', 'time', 'news', 'reports', 'Udaipur', 'capital', 'Ajmer', 'virus', 'hospital']\n",
            "['Moroccan', 'Corona', 'Minister', 'virus', 'Minister Amara', 'Amara', 'cases', 'regular', 'duties', 'technical', 'days', 'remote', 'headache', 'instructions', 'tests', 'fatigue', 'work', 'medical', 'doctors', 'Morocco', 'Baghdad', 'infection']\n",
            "['patients', 'number', 'corona-infected', 'Rajasthan', 'infected patients', 'Kota', 'infected', 'Jodhpur', 'Bhilwara', 'Udaipur', 'Jaipur', 'Nagaur', 'Pali', 'Ajmer', 'Chittorgarh', 'Tonk', 'Jaisalmer', 'corona', 'Bharatpur', 'infection', 'Jhalawar']\n",
            "['people', 'Jaipur', 'Rajasthan', 'infected', 'Corona', 'government', 'cases', 'today', 'number', 'cold', 'cough', 'fever', 'positive', 'Gehlot', 'medicine', 'Jaisalmer', 'Sawai', 'Dausa', 'Bhilwara', 'Italy', 'Jodhpur', 'Jhunjhunu', 'infection', 'corona', 'Rajdhani', 'Tonk', 'Nagaur', 'lockdown', 'virus', 'Sawai Madhopur']\n",
            "['Corona', 'Actor', 'Virus', 'American', 'Content', 'number', 'actor', 'requirement', 'article', 'Hanks', 'Renowned', 'respect', 'query', 'News', 'contact', 'wife', 'Hiru', 'permission', 'March', 'deaths', 'Editor', 'Rita', 'virus', 'France', 'Spain', 'Tom Hanks', 'Rita Wilson', 'India', 'Sri Lanka']\n",
            "['Nursing', 'AIIMS', 'officers', 'COVID', 'COVID-19 ward', 'COVID-19', 'medical team', 'patients', 'ward', 'services', 'nurses', 'Medical', 'health', 'India', 'teams', 'department', 'Yadav', 'duty', 'positive', 'society', 'Madhya Pradesh', 'Chief Nursing Officer', 'infection', 'communicable disease', 'Trauma Center', 'quarantine', 'Oncology', 'nursing', 'surfacing', 'Bihar', 'depression', 'blood donation', 'lockdown', 'New Delhi', 'Uttar Pradesh', 'coronavirus']\n",
            "['Virus', 'Corona', 'Infected', 'Patients', 'Sargodha', 'spokesman', '23rd', 'treatment', 'people', 'public', 'arrangements', 'directives', 'hospital', 'district', 'suspect', 'Muhammad', 'Pakistan', 'department', 'SARGODHA', 'Dera Ghazi Khan', 'virus']\n",
            "['Malegaon', 'infected', 'corona', 'Content', 'report', 'patients', 'requirement', 'district', 'article', 'respect', 'query', 'contact', 'News', 'India', 'United', 'permission', 'city', 'General Hospital', 'Jeevan', 'Nashik', 'RDS', 'SS']\n",
            "['persons', 'infected', 'Madhya', 'Corona', 'Pradesh', 'Number', 'Madhya Pradesh', 'Content', 'number', 'Bhopal', 'people', 'requirement', 'article', 'respect', 'awaaz', 'query', 'contact', 'indian', 'permission', 'Digital', 'Jabalpur', 'Indore', 'infection', 'India', 'Ujjain']\n",
            "['Italy', 'citizens', 'Macedonian', 'corona', 'virus', 'Ministry', 'Meta.mk', 'Affairs', 'Foreign', 'Foreign Affairs Ministry', 'corona virus', 'Macedonian Consulate', 'region', 'measures', 'Consulate', 'Romana', 'Emilia', 'period', 'Veneto', 'Italian', 'Italians', 'Venice', 'venice', 'Rome', 'Lombardia', 'informs', 'MFA', 'Embassy']\n",
            "['therapy', 'infected', 'corona', 'patient', 'condition', 'Plasma', 'cost', 'family', 'people', 'Coronavirus', 'plasma', 'days', 'government', 'Jamaat', 'house', 'security', 'guard', 'rest', 'process', 'years', 'father', 'The age', 'All 4', 'hospital', 'coronavirus', 'ward']\n",
            "['patients', 'number', 'Rajasthan', 'infected', 'total', 'corona', 'capital Jaipur', 'Jaipur', 'Sunday', 'Sikar', 'capital', 'Hanumangarh', 'Bharatpur', 'Banswara', 'people', 'coronavirus', 'Jhalawar', 'Jodhpur', 'Kota', 'Ajmer', 'Dholpur', 'Udaipur', 'Nagaur', 'virus', 'district', 'Coronavirus']\n",
            "['repair', 'renovation', 'patients', 'work', 'infected', 'Chattogram', 'virus', 'Corona', 'General', 'Estblishment', 'Hospital', 'ward', 'General Hospital', 'Tender/Proposal Document', 'Corona virus', 'Tender/Proposal', 'Document', 'PUBLIC', 'Time', 'Purta', 'Local', 'Bangladesh', 'Floor', 'Security', 'Bhaban', 'BDT', 'PUBLIC WORKS DEPARTMENT', 'Lot']\n",
            "['Bahrain', 'case', 'Corona-virus', 'Ministry', 'high infection', 'contact', 'patient', 'Medical', 'Content', 'school', 'high', 'individuals', 'symptoms', 'infected', 'Coronavirus', 'Health', 'COVID-19', 'days', 'Dubai', 'kindergarten', 'Kindergarten', 'MANAMA', 'infection', 'quarantine', 'Iran', 'public health', 'Bahrain International Airport', 'school bus', 'virus', 'temperature', 'Sitra']\n",
            "['Sargodha', 'Corona', 'patients', 'Virus', 'Corona Virus', 'virus', 'district', 'pilgrims', 'spokesman', 'treatment', 'arrangements', 'people', 'hospital', 'Ghazi', 'Khan', 'Dera', 'Quarantine', 'center', 'department', 'Dera Ghazi Khan']\n",
            "['infection', 'Corona', 'control', 'Corona infection', 'Corona virus', 'public health', 'Høie', 'numbers', 'virus', 'people', 'weeks', 'measures', 'public', 'Health', 'Stoltenberg', 'daily', 'development', 'Norway', 'positive', 'hygiene', 'infection control', 'epidemic', 'Europe', 'Norwegian', 'intensive care', 'lose control']\n",
            "['Babylon', 'Corona', 'virus', 'death', 'crisis cell', 'Friday', 'today', 'Cell', 'Crisis', 'kidneys', 'number', 'failure', 'system', 'respiratory', 'Hilla', 'collapse', 'person', 'media', 'years', 'infected', 'respiratory system']\n",
            "['Corona', 'Infected', 'Mardan', 'Virus', 'PTI', 'positive coronavirus', 'people', 'corona', 'positive', 'coronavirus', 'infection', 'Manga', 'time', 'touch', 'disease', 'distressed', 'area', 'number', 'Pakistan', 'cases', 'Abdul', 'Salam', 'Pakhtukhwa', 'blood test', 'quarantine', 'Pakistan Tehreek-e-Insaf', 'Afridi', 'repentance', 'province']\n",
            "['Preventive', 'Corona', 'Reviews', 'Minister', 'Measures', 'corona measures', 'Kohat Development', 'Kohat', 'Government', '22nd', 'Development', 'Municipal', 'Bangash', 'problems', 'resolution', 'resources', 'public', 'spreading', 'Office', 'steps', 'COVID-19', 'Khyber Pakhtunkhwa', 'Muhammad', 'Pakistan', 'Information Technology', 'corona', 'KOHAT', 'Tehsil', 'CM']\n",
            "['Virus', 'Corona', 'persons', 'country', 'number', 'increase', 'Content', 'individual', 'requirement', 'total', 'article', 'identification', 'respect', 'Epidemiology', 'Unit', 'Digital', 'query', 'News', 'permission', 'Hiru', 'contact', 'Sri Lanka']\n",
            "['Works', 'renovation', 'repair', 'Tender', 'patients', 'infected', 'Estblishment', 'virus', 'Chattogram', 'Corona', 'Department', 'General', 'Hospital', 'Public', 'Bangladesh', 'General Hospital', 'Public Works Department', 'ward', 'Bangladesh Contact', 'tender', 'Official', 'Contact', 'Tender/Proposal', 'Inviting', 'Technical', 'Unit', 'Thana', 'Chittagong', 'City', 'Procurement', 'Dhaka']\n",
            "['Virus', 'persons', 'infected', 'Corona', 'yesterday', 'Colombo', 'Content', 'quarantine', 'residents', 'treatment', 'number', 'patients', 'Medical', 'requirement', 'Castle', 'article', 'Commander', 'Colombo Municipal Council', 'Lieutenant General', 'antibiotics', 'Sri Lanka', 'Pettah', 'virus', 'Paracetamol']\n",
            "['Virus', 'Corona', 'Measures', 'Precautionary', 'Outbreak', 'Director Health', 'Corona Virus', 'Health', 'district', 'case', 'people', 'Director', 'hands', 'citizens', 'area', 'instructions', 'checkup', 'facilities', 'rumors', 'medical', 'sneezing', 'Pakistan', 'Rana', 'flue', 'fever', 'department', 'tissue paper', 'SARGODHA', 'corona virus']\n",
            "['corona', 'infected', 'positive cases', 'coronavirus', 'positive', 'cases', 'proper', 'patients', 'district', 'treatment', 'Saqib', 'Raza', 'Commissioner', 'official', 'Swat', 'Aslam', 'senior', 'Deputy', 'Saturday', 'Saidu', 'MINGORA', 'Swat district', 'Saidu Sharif', 'pandemic']\n",
            "['infected', 'housing', 'Corona', 'workers', 'schools', 'infection', 'teams', 'residence', 'virus', 'number', 'labor', 'Cooperative', 'Ministry', 'Salmiya', 'Health', 'Society', 'procedures', 'rest', 'Asian', 'medical', 'quarantine', 'Egyptian', 'WhatsApp', 'coronavirus', 'KUWAIT CITY']\n",
            "['number', 'people', 'Rajasthan', 'curfew', 'corona', 'time', 'Jaipur', 'case', 'Sardarshahar', 'Tonk', 'roofs', 'coronavirus', 'streets', 'houses', 'Barricades', 'Chirdu', 'Churu', 'Parkota', 'administration', 'Bhilwara', 'SMS', 'Jodhpur', '17 people', 'drones', 'virus', 'Coronavirus']\n",
            "['Covid-19', 'optimism', 'assoc.', 'figures', 'early', 'intensive care', 'coronavirus patients', 'patients', 'care', 'intensive', 'Netherlands', 'people', 'ICUs', 'total', 'coronavirus', 'Gommers', 'Sunday', 'number', 'a.m.', 'outflow', 'satisfied', 'inflow', 'Monday', 'NICE', 'pandemic']\n",
            "['infected', 'Majority', 'patients', 'country', 'virus', 'Agra', 'Corona', 'infected people', 'samples (infection', 'people', 'corona', 'Health', 'city', 'Government', 'samples', 'International', 'China', 'Content', 'health services', 'Delhi', 'Italy', 'infection', 'department', 'India', 'Hindustan', 'lakh', 'Taj Mahal', 'Chinese', 'World Health Organization', 'district hospital', 'hospital', 'camping', 'international standard', 'corona virus', 'wards']\n",
            "['corona', 'virus', 'Belgium', 'cat', 'corona virus', 'foreign media', 'veterinary surgeons', 'Content', 'media', 'foreign', 'requirement', 'infected', 'veterinary', 'article', 'surgeons', 'respect', 'contact', 'query', 'News', 'Hiru', 'permission', 'Hong Kong', 'feline', 'infection', 'Sri Lanka', 'public health']\n",
            "['Bahrain', 'Patients', 'Virus', 'Park', 'case', 'Gulf', 'measure', 'park', 'weeks', 'Medical', 'beds', 'Tuesday', 'unit', 'coronavirus', 'respiratory', 'infected', 'equipped', 'Manama', 'Pakistan', 'Saudi Arabia', 'ministry', 'Nayef', 'military hospital', 'Gulf country', 'intensive care unit', 'respiratory disease', 'bridge', 'novel coronavirus', 'COVID-19', 'Sheikh']\n",
            "['Islamabad', 'infected', 'corona', 'death', 'woman', 'corona virus', 'virus', 'treatment', 'patient', 'medical', 'Britain', 'pertinent', 'years', 'test', 'hospital', 'number', 'ventilator', 'lungs', 'Pakistan', 'federal capital', 'twin cities', 'ward']\n",
            "['Virus', 'Corona', 'worldwide', 'Deaths', 'increase', 'Corona Virus', 'number', 'India', 'Content', 'deaths', 'persons', 'requirement', 'article', 'respect', 'week', 'Indian', 'United States', 'Hubei', 'epicenter', 'Sri Lanka', 'Wuhan', 'Singapore', 'China', 'lockdown', 'virus', 'pandemic', 'Covid-19', 'peak']\n",
            "['Corona', 'Monaco', 'Albert', 'Prince', 'virus', 'Albert II', 'condition', 'Royal', 'Palace', 'statement', 'stable', 'testing', 'health', 'NINA', 'positive', 'infection', 'Baghdad', 'concern', 'palace', 'Royal Palace', 'corona virus']\n",
            "['worldwide', 'infected', 'corona', 'dead', 'Hopkins', 'Johns', 'University', 'coronavirus', 'official', 'data', 'people', 'Johns Hopkins University']\n",
            "['Women', 'President', 'Affairs', 'Corona', 'Vice', 'virus', 'Iranian', 'Vice President', 'Corona virus', 'Foreign Policy', 'National', 'Agency', 'News', 'Foreign', 'Policy', 'today', 'Security', 'authorities', 'head', 'country', 'Masoumeh', 'Iranian parliament', 'Hariri', 'Masoumeh Ebtekar']\n",
            "['death', 'Fourth', 'LIVE', 'Maharashtra', 'total', 'number', 'India', 'infected', 'Corona', 'country', 'health workers', 'corona', 'health', 'woman', 'government', 'cases', 'people', 'district', 'workers', 'Thursday', 'stern', 'warning', 'landlords', 'Arabia', 'news', 'Saudi', 'Bhilwara', 'Navi Mumbai', 'Rajasthan', 'Saudi Arabia', 'Mecca', 'kidney', 'Karnataka', 'CM', 'coma', 'Bhilwara district']\n",
            "['wife', 'infection', 'citizen', 'Corona', 'Department', 'Health', 'virus', 'governorate', 'Najaf', 'yesterday', 'media', 'measures', 'Iran', 'contact', 'Mahdi', 'Al-Hakim', 'patient', 'neighborhood', 'today', 'department', 'province']\n",
            "['Corona', 'Iranian', 'virus', 'Parliament', 'Iranian Parliament', 'Thursday', 'Health', 'member', 'infections', 'deaths', 'Beijing', 'Wuhan', 'center', 'mid-January', 'city', 'cancellation', 'Friday prayers', 'Tehran', 'Baghdad', 'infection', 'tweet', 'Twitter', 'Islam', 'Vatican', 'China', 'World Health Organization', '23 provinces', 'Hajjah']\n",
            "['infected', 'risk', 'corona', 'visible', 'asymptomatic', 'symptoms', 'patients', 'South China', 'people', 'percent', 'China', 'Italy', 'infection', 'Nature', 'United States', 'Spain', 'quarantine', 'Iran', 'fever', 'India', 'Hubei province', 'Japan', 'dry cough', 'lakh', 'South Korea', 'Corona', 'pneumonia', 'World Health Organization', 'Germany', 'Coronavirus']\n",
            "['Peoples Medical', 'Hospital (PMCH', 'District Health', 'Medical', 'Hospital', 'Peoples', 'District', 'Health', 'PMCH', 'Corona', 'Karachi', 'patients', 'paramedical', 'doctors', 'Tuesday', 'special', 'directives', 'College', 'Sindh', 'Muhammad', 'department', 'Baloch', 'Memon', 'NAWABSHAH', 'Gulshan', 'Vice Chancellor']\n",
            "['Corona', 'Atulugama', 'sister', 'infected', 'Father', 'person', 'content requirement', 'infected patient', 'area', 'Content', 'Hiru', 'correspondent', 'hospital', 'Covid-19', 'patient', 'Atalugama', 'requirement', 'article', 'respect', 'contact', 'corona', 'Sri Lanka', 'coronavirus']\n",
            "['Dausa', 'administration', 'corona', 'person', 'steps', 'number', 'coronavirus', 'Hotel', 'Nagauri', 'Pulia', 'curfew', 'report', 'positive', 'Allanoor', 'people', 'Mobility', 'Area', 'March', 'wards', 'Jamaat', 'city', 'Delhi', 'time', 'Jaipur', 'Bhilwara', 'Rajasthan', 'Section 144', 'district', 'Coronavirus']\n",
            "['Peoples Medical', 'Hospital (PMCH', 'District Health', 'Medical', 'Content', 'Hospital', 'Peoples', 'District', 'Health', 'Karachi', 'PMCH', 'Corona', 'patients', 'requirement', 'article', 'respect', 'Tuesday', 'special', 'directives', 'Muhammad', 'Sindh', 'Pakistan', 'department', 'Baloch', 'Memon', 'Gulshan', 'Vice Chancellor']\n",
            "['measures', 'virus', 'corona', 'outbreak', 'precautionary', 'corona virus', 'Director Health', 'Health', 'people', 'case', 'citizens', 'district', 'area', 'Corona', 'hands', 'Virus', 'Director', 'checkup', 'facilities', 'medical', 'hospitals', 'reporter', 'availability', 'rumors', 'sneezing', 'Rana', 'flue', 'fever', 'department', 'tissue paper']\n",
            "['ship', 'Diamond', 'cruise', 'Princess', 'members', 'Corona', 'crew', 'virus', 'Indian', 'cruise ship', 'corona virus', 'content requirement', 'crew members', 'corona', 'Content', 'requirement', 'Japan', 'people', 'article', 'respect', 'contact', 'Embassy', 'Japanese', 'Hong Kong', 'infection']\n",
            "['INFECTED', 'CORONA', 'EXCEED', 'DEATHS', 'Corona Virus', 'Virus', 'Corona', 'China', 'Content', 'Wuhan', 'quarantine', 'Ports', 'yesterday', 'General', 'number', 'woman', 'young', 'Moneragala', 'General Hospital', 'Sri Lankans', 'Russian', 'Vavuniya', 'Kuala Lumpur', 'Diyatalawa', 'island', 'Sri Lanka', 'Malaysia', 'South Korea', 'Singapore', 'lockdown', 'virus', 'Jaffna', 'Siberia', 'Badulla', 'Colombo']\n",
            "['infected', 'Worldwide', 'cases', 'people', 'Corona', 'Health Minister', 'corona infection', 'Yossi Cohen', 'Minister', 'Litzman', 'contact', 'deaths', 'Health', 'Cohen', 'Yossi', 'chief', 'National', 'Security', 'Mossad', 'Shabbat', 'Italy', 'France', 'infection', 'Spain', 'Europe', 'news agency', 'minister', 'corona', 'Benjamin Netanyahu', 'Donald Trump', 'lakh', 'National Security Advisor', 'Israel', 'US President', 'virus', 'Prime Minister', 'Mir', 'Coronavirus', 'coronavirus', 'United Nations']\n",
            "['Bahrain', 'Patients', 'Virus', 'Park', 'case', 'measure', 'Gulf', 'unit', 'parking', 'weeks', 'Medical', 'beds', 'patients', 'Tuesday', 'equipped', 'coronavirus', 'respiratory', 'Manama', 'Saudi Arabia', 'ministry', 'Nayef', 'military hospital', 'Gulf country', 'intensive care unit', 'respiratory disease', 'park', 'hospital', 'bridge', 'COVID-19', 'novel coronavirus', 'Sheikh']\n",
            "['Bahrain', 'park', 'Covid-19', 'cases', 'Gulf', 'measure', 'beds', 'unit', 'coronavirus', 'weeks', 'Medical', 'Tuesday', 'equipped', 'infected', 'respiratory', 'Manama', 'Saudi Arabia', 'ministry', 'Nayef', 'military hospital', 'Gulf country', 'intensive care unit', 'respiratory disease', 'bridge', 'novel coronavirus', 'COVID-19', 'Sheikh']\n",
            "['Corona', 'Bihar', 'responsible', 'person infected', 'infected persons', 'persons', 'Kumar', 'Content', 'infected', 'requirement', 'Department', 'article', 'respect', 'Patna', 'query', 'Singh', 'News', 'contact', 'India', 'Rohtas', 'Additional Director General', 'Siwan', 'infection', 'Buxar', 'Lokesh', 'virus', 'video conferencing', 'Nalanda', 'negligence']\n",
            "['Bahrain', 'patients', 'virus', 'park', 'case', 'Gulf', 'measure', 'beds', 'unit', 'weeks', 'Medical', 'Tuesday', 'coronavirus', 'equipped', 'infected', 'respiratory', 'Manama', 'Saudi Arabia', 'ministry', 'Nayef', 'military hospital', 'hc', 'Gulf country', 'intensive care unit', 'respiratory disease', 'bridge', 'novel coronavirus', 'COVID-19', 'Sheikh']\n",
            "['corona', 'Tragic', 'fighter', 'death', 'General Hospital', 'doctor', 'Hospital', 'Moyeen', 'Dhaka', 'Health', 'Covid-19', 'Sylhet', 'General', 'Content', 'Medical', 'director', 'professionals', 'healthcare', 'The doctors', 'quarantine', 'air ambulance', 'BSMMU', 'intensive care unit', 'ABM', 'director general (DG)', 'Corona', 'ambulance', 'Brigadier General', 'social media', 'ventilator', 'SARS-CoV', 'virus', 'respiratory failure', 'hospital', 'hospital authority', 'COVID-19', 'coronavirus', 'Bangladesh']\n",
            "['Swat', 'Patient', 'Discharged', 'Infected', 'Corona', 'Hospital', 'Swat District', 'corona patients', 'Buner district', 'district', 'treatment', 'blood', 'Wednesday', 'Buner', '@FahadShabbir', 'Khazakhela', 'minutes', 'Shabbir', 'Odigram', '08th', 'Swat district', 'Pakistan', 'infection', 'corona', 'Saidu Sharif', 'virus', 'hospital', 'coronavirus']\n",
            "['Bahrain', 'patients', 'virus', 'park', 'case', 'Gulf', 'beds', 'unit', 'hospital', 'coronavirus', 'measure', 'Medical', 'Tuesday', 'field hospital', 'Manama', 'engineering', 'Dubai', 'emirate', 'ministry', 'Nayef', 'military hospital', 'Gulf country', 'intensive care unit', 'fair dealing', 'United Arab Emirates', 'respiratory disease', 'bridge', 'novel coronavirus', 'COVID-19', 'Sheikh']\n",
            "['wards', 'ICUs', 'ministry', 'virus', 'Malaysian', 'workers', 'Healthcare', 'Insight', 'patients', 'Covid-19', 'intensive', 'care', 'Hisham', 'director-general', 'Noor', 'units', 'Abdullah', 'Health', 'positive', 'coronavirus', 'mosque', 'gatherings', 'healthcare', 'intensive care units']\n",
            "['infected', 'patients', 'Corona', 'Maharashtra', 'Number', 'India', 'Content', 'number', 'requirement', 'article', 'deaths', 'respect', 'contact', 'query', 'News', 'Hiru', 'Virus', 'persons', 'permission', 'Editor', 'Digital', 'Mumbai', 'Sri Lanka']\n",
            "['Health', 'Department', 'Basra', 'measures', 'delegation', 'Corona', 'medical', 'Chinese', 'virus', 'Health Department', 'purpose', 'houses', 'guidelines', 'places', 'treatment', 'separate', 'specialist', 'people', 'doctors', 'Al-Tamimi']\n",
            "['treatment', 'corona', 'Kanika', 'infected', 'singer', 'Bollywood', 'people', 'Plasma', 'reason', 'Kanika Kapoor', 'Bollywood singer', 'plasma', 'KGMU', 'Kapoor', 'coronavirus', 'antibodies', 'transfusion', 'medicine', 'evening', 'patients', 'department', 'PGI', 'transfusion medicine', 'infection', 'virus', 'Coronavirus', 'blood']\n",
            "['deaths', 'infected', 'Italy', 'Corona', 'China', 'infection cases', 'total number', 'number', 'infection', 'people', 'cases', 'toll', 'Iran', 'total', 'patients', 'lakhs', 'dead', 'time', 'global', 'Punjab province', 'France', 'Pakistan', 'Philippines', 'epidemic', 'Russia', 'lakh', 'virus', 'coronavirus', 'Indonesia']\n",
            "['Bahrain', 'patients', 'virus', 'park', 'case', 'Services commander', 'Gulf', 'officials', 'precautionary', 'unit', 'beds', 'commander', 'Services', 'reporters', 'Medical', 'Tuesday', 'inauguration', 'Royal', 'record', 'MANAMA', 'Manama', 'Gulf country', 'intensive care unit', 'respiratory disease', 'novel coronavirus', 'COVID-19', 'coronavirus', 'Sheikh']\n",
            "['Netherlands', 'patients', 'Covid-19', 'Covid-19 patients', 'Care (NVIC', 'Gommers', 'health', 'Dutch', 'system', 'Care', 'summer', 'NVIC', 'percent', 'letter', 'capacity', 'assumptions', 'report', 'joint', 'years', 'public', 'healthcare', 'vaccine', 'acute care', 'intensive care unit', 'public health']\n",
            "['infected', 'virus', 'list', 'Corona', 'Kalaburagi', 'tally', 'COVID-19', 'district Covid-19', 'infected persons', 'district', 'persons', 'Content', 'cases', 'Family', 'people', 'City', 'administration', 'requirement', 'article', 'respect', 'query', 'Vijayapura', 'survey', 'department', 'India', 'MSP', 'Coronavirus', 'Covid-19']\n",
            "['country', 'plasma', 'Corona', 'therapy', 'patient', 'delhi', 'Ladenge', 'plasma therapy', 'ventilator', 'Hospital', 'trial', 'discussions', 'infected', 'Sunday', 'Delhi', 'condition', 'Doctors', 'news', 'breathing', 'Saket', 'NIC', 'AIIMS', 'Jhajjar', 'corona', 'Tablighi Jamaat', 'pneumonia']\n",
            "['Shishu', 'beds', 'Rangpur', 'Hospital', 'Rangpur division', 'Health', 'Installation', 'unit', 'treatments', 'division', 'facilities', 'patients', 'health services', 'intensive care unit', 'DHAKA', 'Dhaka', 'Corona', 'upazila', 'coronavirus', 'COVID-19', 'Bangladesh']\n",
            "['Italy', 'Patient', 'Italy’s Patient', 'virus patients', 'intensive care', 'virus', 'care', 'intensive', 'Mattia', 'small', 'Mojoli', 'life', 'spread', 'hospital', 'region', 'head', 'government', 'positive', 'disease', 'RAI', 'health care', 'Italian', 'Italians', 'infectious disease', 'oxygen', 'Lombardy', 'Cremona', 'Japan', 'Medina', 'China', 'Unilever', 'Getty Images', 'scrambling', 'coronavirus', 'Pavia', 'wards']\n",
            "['Virus', 'Corona', 'Measures', 'Threat', 'Safety', 'Deputy Commissioner', 'deputy commissioners', 'Additional Commissioner', 'Corona Virus', 'Corona virus', 'Commissioner', 'protective steps', 'virus', 'Deputy', 'country', 'persons', 'protective', 'Sindh', 'Pakistan', 'Samo', 'Allah', 'Iran', 'department', 'China', 'NAWABSHAH', 'ward', 'Sanghar', 'province', 'Feroze']\n",
            "['Oman', 'Jaipur', 'infected', 'havoc', 'people', 'Corona', 'People', 'district', 'area', 'lockdown', 'hand', 'Howrah', 'North', 'report', 'patients', 'order', 'government', 'Rajasthan', 'officials', 'Ajmer', 'religious', 'places', 'mild', 'North 24 Parganas', 'Jodhpur', 'Dargah', 'West Bengal', 'Iran', 'Ajmer district', 'force', 'Chishti', 'Jaisalmer', 'virus']\n",
            "['Bahrain', 'infected', 'corona', 'patients', 'Iran', 'treatment', 'virus', 'Health', 'citizens', 'Ministry', 'people', 'February', 'specialized', 'month', 'supervision', 'medical', 'staff', 'tests', 'laboratory', 'care', 'status', 'online', 'isolation', 'Manama', 'HIV', 'Corona', 'Bahrain International Airport', 'Coronavirus', 'register']\n",
            "['Norway', 'Measures', 'Infection', 'Rate', 'Corona', 'Growth', 'Strict', 'health authorities', 'infection', 'measures', 'epidemic', 'authorities', 'health', 'patient', 'report', 'hospital', 'March', 'strict', 'vaccination', 'point', 'people', 'population', 'situation', 'corona', 'Norwegian', 'virus']\n",
            "['manner', 'Corona-infected', 'patients', 'vehicles', 'Pakistan', 'Gilgit Baltistan', 'Punjab', 'Mirpur', 'people', 'Army', 'Baltistan', 'Gilgit', 'region', 'area', 'Local', 'officers', 'Corona', 'Kashmir', 'Punjab province', 'POK', 'Pakistan Occupied Kashmir', 'PoK', 'quarantine', 'epidemic', 'corona', 'Gilgit-Baltistan']\n",
            "['Corona', 'Virus', 'hospital', 'person', 'Corona Virus', 'Content', 'persons', 'requirement', 'article', 'respect', 'query', 'News', 'contact', 'infected', 'Hiru', 'permission', 'Digital', 'individual', 'country', 'Editor', 'number', 'quarantine', 'Sri Lanka', 'Colombo']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkyYT7bDe6ph",
        "colab_type": "code",
        "outputId": "4c66279b-c748-4acb-f99e-07adb56a0f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "document =  {}\n",
        "\n",
        "for country in eu:\n",
        "  document[country] = []\n",
        "document['Latvia'].append('new')\n",
        "x = document['Latvia']\n",
        "print(x)\n",
        "# x.append(\"key\")\n",
        "print(document)\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['new']\n",
            "{'Austria': [], 'Belgium': [], 'Latvia': ['new'], 'Bulgaria': [], 'Lithuania': [], 'Croatia': [], 'Luxembourg': [], 'Cyprus': [], 'Malta': [], 'Czechia': [], 'Netherlands': [], 'Denmark': [], 'Poland': [], 'Estonia': [], 'Portugal': [], 'Finland': [], 'Romania': [], 'France': [], 'Slovakia': [], 'Germany': [], 'Slovenia': [], 'Greece': [], 'Spain': [], 'Hungary': [], 'Sweden': [], 'Ireland': [], 'Italy': []}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoqHxqeylSfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "def fetch_new_stories(params={}):\n",
        "  fetched_stories = []\n",
        "  stories = None\n",
        "  keywords = []\n",
        "  keyws = ''\n",
        "\n",
        "#  while stories is None or len(stories) < 1000:\n",
        "  while stories is None or len(fetched_stories) < 60000:\n",
        "    try:\n",
        "      response = api_instance.list_stories(**params)\n",
        "      for story in api_response.stories:\n",
        "        for keyword in story.keywords:\n",
        "          keywords.append(keyword)\n",
        "          keyws = ' '.join(keywords)\n",
        "        intersect = list(set(keywords).intersection(eu))\n",
        "\n",
        "        if(len( intersect )>0):\n",
        "          remain = [s for s in keywords if s != intersect[0] ]\n",
        "        \n",
        "          document[intersect[0]].append(remain)\n",
        "          #print(intersect[0],document[intersect[0]])\n",
        "\n",
        "        #entities = client.Entities({\"text\": keyws})\n",
        "        #elsa = client.Elsa({'text': keyws})\n",
        "        #print(elsa)\n",
        "        #if(entities['entities'].get(\"location\")) != None:\n",
        "        #  print(entities['entities']['location'])\n",
        "        keywords=[]\n",
        "    except ApiException as e:\n",
        "      if ( e.status == 429 ):\n",
        "        print('Usage limits are exceeded. Waiting for 60 seconds...')\n",
        "        time.sleep(60)\n",
        "        continue\n",
        "\n",
        "    stories = response.stories\n",
        "    params['cursor'] = response.next_page_cursor\n",
        "\n",
        "    fetched_stories += stories\n",
        "    print(\"Fetched %d stories. Total story count so far: %d\" %\n",
        "      (len(stories), len(fetched_stories)))\n",
        "\n",
        "  return fetched_stories, document"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8QhDKELpX68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1be306c-19dc-4a5a-ded6-b30c8d7c74e6"
      },
      "source": [
        "output = []\n",
        "full_text = []\n",
        "# for story in stories:\n",
        "#   intersect = list(set(story.keywords).intersection(eu))\n",
        "#   if len(intersect) == 1 :\n",
        "#     output = np.append(intersect,story.keywords)\n",
        "#     full_text = np.append(full_text,output)\n",
        "#   output=[]\n",
        "\n",
        "full_text = [\" \".join(story.keywords) for story in stories if (len(list(set(story.keywords).intersection(eu))) == 1)]\n",
        "\n",
        "print(full_text[0])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona virus northern family Iraqi Italy Iraqi Embassy Embassy infected statement stable Rome people health NINA Baghdad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQEhp1rpmTzi",
        "colab_type": "code",
        "outputId": "52a9c698-6e5d-44cc-908b-d7107d82774b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "stories, data = fetch_new_stories(opts)\n",
        "print(len(data))\n",
        "print('************')\n",
        "print(\"Fetched %d stories mentioning 'corona' in the title, are in English, and were published between %s and %s\" %\n",
        "(len(stories), opts['published_at_start'], opts['published_at_end']))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetched 100 stories. Total story count so far: 100\n",
            "Fetched 100 stories. Total story count so far: 200\n",
            "Fetched 100 stories. Total story count so far: 300\n",
            "Fetched 100 stories. Total story count so far: 400\n",
            "Fetched 100 stories. Total story count so far: 500\n",
            "Fetched 100 stories. Total story count so far: 600\n",
            "Fetched 100 stories. Total story count so far: 700\n",
            "Fetched 100 stories. Total story count so far: 800\n",
            "Fetched 100 stories. Total story count so far: 900\n",
            "Fetched 100 stories. Total story count so far: 1000\n",
            "Fetched 100 stories. Total story count so far: 1100\n",
            "Fetched 100 stories. Total story count so far: 1200\n",
            "Fetched 100 stories. Total story count so far: 1300\n",
            "Fetched 100 stories. Total story count so far: 1400\n",
            "Fetched 100 stories. Total story count so far: 1500\n",
            "Fetched 100 stories. Total story count so far: 1600\n",
            "Fetched 100 stories. Total story count so far: 1700\n",
            "Fetched 100 stories. Total story count so far: 1800\n",
            "Fetched 100 stories. Total story count so far: 1900\n",
            "Fetched 100 stories. Total story count so far: 2000\n",
            "Fetched 100 stories. Total story count so far: 2100\n",
            "Fetched 100 stories. Total story count so far: 2200\n",
            "Fetched 100 stories. Total story count so far: 2300\n",
            "Fetched 100 stories. Total story count so far: 2400\n",
            "Fetched 100 stories. Total story count so far: 2500\n",
            "Fetched 100 stories. Total story count so far: 2600\n",
            "Fetched 100 stories. Total story count so far: 2700\n",
            "Fetched 100 stories. Total story count so far: 2800\n",
            "Fetched 100 stories. Total story count so far: 2900\n",
            "Fetched 100 stories. Total story count so far: 3000\n",
            "Fetched 100 stories. Total story count so far: 3100\n",
            "Fetched 100 stories. Total story count so far: 3200\n",
            "Fetched 100 stories. Total story count so far: 3300\n",
            "Fetched 100 stories. Total story count so far: 3400\n",
            "Fetched 100 stories. Total story count so far: 3500\n",
            "Fetched 100 stories. Total story count so far: 3600\n",
            "Fetched 100 stories. Total story count so far: 3700\n",
            "Fetched 100 stories. Total story count so far: 3800\n",
            "Fetched 100 stories. Total story count so far: 3900\n",
            "Fetched 100 stories. Total story count so far: 4000\n",
            "Fetched 100 stories. Total story count so far: 4100\n",
            "Fetched 100 stories. Total story count so far: 4200\n",
            "Fetched 100 stories. Total story count so far: 4300\n",
            "Fetched 100 stories. Total story count so far: 4400\n",
            "Fetched 100 stories. Total story count so far: 4500\n",
            "Fetched 100 stories. Total story count so far: 4600\n",
            "Fetched 100 stories. Total story count so far: 4700\n",
            "Fetched 100 stories. Total story count so far: 4800\n",
            "Fetched 100 stories. Total story count so far: 4900\n",
            "Fetched 100 stories. Total story count so far: 5000\n",
            "Fetched 100 stories. Total story count so far: 5100\n",
            "Fetched 100 stories. Total story count so far: 5200\n",
            "Fetched 100 stories. Total story count so far: 5300\n",
            "Fetched 100 stories. Total story count so far: 5400\n",
            "Fetched 100 stories. Total story count so far: 5500\n",
            "Fetched 100 stories. Total story count so far: 5600\n",
            "Fetched 100 stories. Total story count so far: 5700\n",
            "Fetched 100 stories. Total story count so far: 5800\n",
            "Fetched 100 stories. Total story count so far: 5900\n",
            "Fetched 100 stories. Total story count so far: 6000\n",
            "Fetched 100 stories. Total story count so far: 6100\n",
            "Fetched 100 stories. Total story count so far: 6200\n",
            "Fetched 100 stories. Total story count so far: 6300\n",
            "Fetched 100 stories. Total story count so far: 6400\n",
            "Fetched 100 stories. Total story count so far: 6500\n",
            "Fetched 100 stories. Total story count so far: 6600\n",
            "Fetched 100 stories. Total story count so far: 6700\n",
            "Fetched 100 stories. Total story count so far: 6800\n",
            "Fetched 100 stories. Total story count so far: 6900\n",
            "Fetched 100 stories. Total story count so far: 7000\n",
            "Fetched 100 stories. Total story count so far: 7100\n",
            "Fetched 100 stories. Total story count so far: 7200\n",
            "Fetched 100 stories. Total story count so far: 7300\n",
            "Fetched 100 stories. Total story count so far: 7400\n",
            "Fetched 100 stories. Total story count so far: 7500\n",
            "Fetched 100 stories. Total story count so far: 7600\n",
            "Fetched 100 stories. Total story count so far: 7700\n",
            "Fetched 100 stories. Total story count so far: 7800\n",
            "Fetched 100 stories. Total story count so far: 7900\n",
            "Fetched 100 stories. Total story count so far: 8000\n",
            "Fetched 100 stories. Total story count so far: 8100\n",
            "Fetched 100 stories. Total story count so far: 8200\n",
            "Fetched 100 stories. Total story count so far: 8300\n",
            "Fetched 100 stories. Total story count so far: 8400\n",
            "Fetched 100 stories. Total story count so far: 8500\n",
            "Fetched 100 stories. Total story count so far: 8600\n",
            "Fetched 100 stories. Total story count so far: 8700\n",
            "Fetched 100 stories. Total story count so far: 8800\n",
            "Fetched 100 stories. Total story count so far: 8900\n",
            "Fetched 100 stories. Total story count so far: 9000\n",
            "Fetched 100 stories. Total story count so far: 9100\n",
            "Fetched 100 stories. Total story count so far: 9200\n",
            "Fetched 100 stories. Total story count so far: 9300\n",
            "Fetched 100 stories. Total story count so far: 9400\n",
            "Fetched 100 stories. Total story count so far: 9500\n",
            "Fetched 100 stories. Total story count so far: 9600\n",
            "Fetched 100 stories. Total story count so far: 9700\n",
            "Fetched 100 stories. Total story count so far: 9800\n",
            "Fetched 100 stories. Total story count so far: 9900\n",
            "Fetched 100 stories. Total story count so far: 10000\n",
            "Fetched 100 stories. Total story count so far: 10100\n",
            "Fetched 100 stories. Total story count so far: 10200\n",
            "Fetched 100 stories. Total story count so far: 10300\n",
            "Fetched 100 stories. Total story count so far: 10400\n",
            "Fetched 100 stories. Total story count so far: 10500\n",
            "Fetched 100 stories. Total story count so far: 10600\n",
            "Fetched 100 stories. Total story count so far: 10700\n",
            "Fetched 100 stories. Total story count so far: 10800\n",
            "Fetched 100 stories. Total story count so far: 10900\n",
            "Fetched 100 stories. Total story count so far: 11000\n",
            "Fetched 100 stories. Total story count so far: 11100\n",
            "Fetched 100 stories. Total story count so far: 11200\n",
            "Fetched 100 stories. Total story count so far: 11300\n",
            "Fetched 100 stories. Total story count so far: 11400\n",
            "Fetched 100 stories. Total story count so far: 11500\n",
            "Fetched 100 stories. Total story count so far: 11600\n",
            "Fetched 100 stories. Total story count so far: 11700\n",
            "Fetched 100 stories. Total story count so far: 11800\n",
            "Fetched 100 stories. Total story count so far: 11900\n",
            "Fetched 100 stories. Total story count so far: 12000\n",
            "Fetched 100 stories. Total story count so far: 12100\n",
            "Fetched 100 stories. Total story count so far: 12200\n",
            "Fetched 100 stories. Total story count so far: 12300\n",
            "Fetched 100 stories. Total story count so far: 12400\n",
            "Fetched 100 stories. Total story count so far: 12500\n",
            "Fetched 100 stories. Total story count so far: 12600\n",
            "Fetched 100 stories. Total story count so far: 12700\n",
            "Fetched 100 stories. Total story count so far: 12800\n",
            "Fetched 100 stories. Total story count so far: 12900\n",
            "Fetched 100 stories. Total story count so far: 13000\n",
            "Fetched 100 stories. Total story count so far: 13100\n",
            "Fetched 100 stories. Total story count so far: 13200\n",
            "Fetched 100 stories. Total story count so far: 13300\n",
            "Fetched 100 stories. Total story count so far: 13400\n",
            "Fetched 100 stories. Total story count so far: 13500\n",
            "Fetched 100 stories. Total story count so far: 13600\n",
            "Fetched 100 stories. Total story count so far: 13700\n",
            "Fetched 100 stories. Total story count so far: 13800\n",
            "Fetched 100 stories. Total story count so far: 13900\n",
            "Fetched 100 stories. Total story count so far: 14000\n",
            "Fetched 100 stories. Total story count so far: 14100\n",
            "Fetched 100 stories. Total story count so far: 14200\n",
            "Fetched 100 stories. Total story count so far: 14300\n",
            "Fetched 100 stories. Total story count so far: 14400\n",
            "Fetched 100 stories. Total story count so far: 14500\n",
            "Fetched 100 stories. Total story count so far: 14600\n",
            "Fetched 100 stories. Total story count so far: 14700\n",
            "Fetched 100 stories. Total story count so far: 14800\n",
            "Fetched 100 stories. Total story count so far: 14900\n",
            "Fetched 100 stories. Total story count so far: 15000\n",
            "Fetched 100 stories. Total story count so far: 15100\n",
            "Fetched 100 stories. Total story count so far: 15200\n",
            "Fetched 100 stories. Total story count so far: 15300\n",
            "Fetched 100 stories. Total story count so far: 15400\n",
            "Fetched 100 stories. Total story count so far: 15500\n",
            "Fetched 100 stories. Total story count so far: 15600\n",
            "Fetched 100 stories. Total story count so far: 15700\n",
            "Fetched 100 stories. Total story count so far: 15800\n",
            "Fetched 100 stories. Total story count so far: 15900\n",
            "Fetched 100 stories. Total story count so far: 16000\n",
            "Fetched 100 stories. Total story count so far: 16100\n",
            "Fetched 100 stories. Total story count so far: 16200\n",
            "Fetched 100 stories. Total story count so far: 16300\n",
            "Fetched 100 stories. Total story count so far: 16400\n",
            "Fetched 100 stories. Total story count so far: 16500\n",
            "Fetched 100 stories. Total story count so far: 16600\n",
            "Fetched 100 stories. Total story count so far: 16700\n",
            "Fetched 100 stories. Total story count so far: 16800\n",
            "Fetched 100 stories. Total story count so far: 16900\n",
            "Fetched 100 stories. Total story count so far: 17000\n",
            "Fetched 100 stories. Total story count so far: 17100\n",
            "Fetched 100 stories. Total story count so far: 17200\n",
            "Fetched 100 stories. Total story count so far: 17300\n",
            "Fetched 100 stories. Total story count so far: 17400\n",
            "Fetched 100 stories. Total story count so far: 17500\n",
            "Fetched 100 stories. Total story count so far: 17600\n",
            "Fetched 100 stories. Total story count so far: 17700\n",
            "Fetched 100 stories. Total story count so far: 17800\n",
            "Fetched 100 stories. Total story count so far: 17900\n",
            "Fetched 100 stories. Total story count so far: 18000\n",
            "Fetched 100 stories. Total story count so far: 18100\n",
            "Fetched 100 stories. Total story count so far: 18200\n",
            "Fetched 100 stories. Total story count so far: 18300\n",
            "Fetched 100 stories. Total story count so far: 18400\n",
            "Fetched 100 stories. Total story count so far: 18500\n",
            "Fetched 100 stories. Total story count so far: 18600\n",
            "Fetched 100 stories. Total story count so far: 18700\n",
            "Fetched 100 stories. Total story count so far: 18800\n",
            "Fetched 100 stories. Total story count so far: 18900\n",
            "Fetched 100 stories. Total story count so far: 19000\n",
            "Fetched 100 stories. Total story count so far: 19100\n",
            "Fetched 100 stories. Total story count so far: 19200\n",
            "Fetched 100 stories. Total story count so far: 19300\n",
            "Fetched 100 stories. Total story count so far: 19400\n",
            "Fetched 100 stories. Total story count so far: 19500\n",
            "Fetched 100 stories. Total story count so far: 19600\n",
            "Fetched 100 stories. Total story count so far: 19700\n",
            "Fetched 100 stories. Total story count so far: 19800\n",
            "Fetched 100 stories. Total story count so far: 19900\n",
            "Fetched 100 stories. Total story count so far: 20000\n",
            "Fetched 100 stories. Total story count so far: 20100\n",
            "Fetched 100 stories. Total story count so far: 20200\n",
            "Fetched 100 stories. Total story count so far: 20300\n",
            "Fetched 100 stories. Total story count so far: 20400\n",
            "Fetched 100 stories. Total story count so far: 20500\n",
            "Fetched 100 stories. Total story count so far: 20600\n",
            "Fetched 100 stories. Total story count so far: 20700\n",
            "Fetched 100 stories. Total story count so far: 20800\n",
            "Fetched 100 stories. Total story count so far: 20900\n",
            "Fetched 100 stories. Total story count so far: 21000\n",
            "Fetched 100 stories. Total story count so far: 21100\n",
            "Fetched 100 stories. Total story count so far: 21200\n",
            "Fetched 100 stories. Total story count so far: 21300\n",
            "Fetched 100 stories. Total story count so far: 21400\n",
            "Fetched 100 stories. Total story count so far: 21500\n",
            "Fetched 100 stories. Total story count so far: 21600\n",
            "Fetched 100 stories. Total story count so far: 21700\n",
            "Fetched 100 stories. Total story count so far: 21800\n",
            "Fetched 100 stories. Total story count so far: 21900\n",
            "Fetched 100 stories. Total story count so far: 22000\n",
            "Fetched 100 stories. Total story count so far: 22100\n",
            "Fetched 100 stories. Total story count so far: 22200\n",
            "Fetched 100 stories. Total story count so far: 22300\n",
            "Fetched 100 stories. Total story count so far: 22400\n",
            "Fetched 100 stories. Total story count so far: 22500\n",
            "Fetched 100 stories. Total story count so far: 22600\n",
            "Fetched 100 stories. Total story count so far: 22700\n",
            "Fetched 100 stories. Total story count so far: 22800\n",
            "Fetched 100 stories. Total story count so far: 22900\n",
            "Fetched 100 stories. Total story count so far: 23000\n",
            "Fetched 100 stories. Total story count so far: 23100\n",
            "Fetched 100 stories. Total story count so far: 23200\n",
            "Fetched 100 stories. Total story count so far: 23300\n",
            "Fetched 100 stories. Total story count so far: 23400\n",
            "Fetched 100 stories. Total story count so far: 23500\n",
            "Fetched 100 stories. Total story count so far: 23600\n",
            "Fetched 100 stories. Total story count so far: 23700\n",
            "Fetched 100 stories. Total story count so far: 23800\n",
            "Fetched 100 stories. Total story count so far: 23900\n",
            "Fetched 100 stories. Total story count so far: 24000\n",
            "Fetched 100 stories. Total story count so far: 24100\n",
            "Fetched 100 stories. Total story count so far: 24200\n",
            "Fetched 100 stories. Total story count so far: 24300\n",
            "Fetched 100 stories. Total story count so far: 24400\n",
            "Fetched 100 stories. Total story count so far: 24500\n",
            "Fetched 100 stories. Total story count so far: 24600\n",
            "Fetched 100 stories. Total story count so far: 24700\n",
            "Fetched 100 stories. Total story count so far: 24800\n",
            "Fetched 100 stories. Total story count so far: 24900\n",
            "Fetched 100 stories. Total story count so far: 25000\n",
            "Fetched 100 stories. Total story count so far: 25100\n",
            "Fetched 100 stories. Total story count so far: 25200\n",
            "Fetched 100 stories. Total story count so far: 25300\n",
            "Fetched 100 stories. Total story count so far: 25400\n",
            "Fetched 100 stories. Total story count so far: 25500\n",
            "Fetched 100 stories. Total story count so far: 25600\n",
            "Fetched 100 stories. Total story count so far: 25700\n",
            "Fetched 100 stories. Total story count so far: 25800\n",
            "Fetched 100 stories. Total story count so far: 25900\n",
            "Fetched 100 stories. Total story count so far: 26000\n",
            "Fetched 100 stories. Total story count so far: 26100\n",
            "Fetched 100 stories. Total story count so far: 26200\n",
            "Fetched 100 stories. Total story count so far: 26300\n",
            "Fetched 100 stories. Total story count so far: 26400\n",
            "Fetched 100 stories. Total story count so far: 26500\n",
            "Fetched 100 stories. Total story count so far: 26600\n",
            "Fetched 100 stories. Total story count so far: 26700\n",
            "Fetched 100 stories. Total story count so far: 26800\n",
            "Fetched 100 stories. Total story count so far: 26900\n",
            "Fetched 100 stories. Total story count so far: 27000\n",
            "Fetched 100 stories. Total story count so far: 27100\n",
            "Fetched 100 stories. Total story count so far: 27200\n",
            "Fetched 100 stories. Total story count so far: 27300\n",
            "Fetched 100 stories. Total story count so far: 27400\n",
            "Fetched 100 stories. Total story count so far: 27500\n",
            "Fetched 100 stories. Total story count so far: 27600\n",
            "Fetched 100 stories. Total story count so far: 27700\n",
            "Fetched 100 stories. Total story count so far: 27800\n",
            "Fetched 100 stories. Total story count so far: 27900\n",
            "Fetched 100 stories. Total story count so far: 28000\n",
            "Fetched 100 stories. Total story count so far: 28100\n",
            "Fetched 100 stories. Total story count so far: 28200\n",
            "Fetched 100 stories. Total story count so far: 28300\n",
            "Fetched 100 stories. Total story count so far: 28400\n",
            "Fetched 100 stories. Total story count so far: 28500\n",
            "Fetched 100 stories. Total story count so far: 28600\n",
            "Fetched 100 stories. Total story count so far: 28700\n",
            "Fetched 100 stories. Total story count so far: 28800\n",
            "Fetched 100 stories. Total story count so far: 28900\n",
            "Fetched 100 stories. Total story count so far: 29000\n",
            "Fetched 100 stories. Total story count so far: 29100\n",
            "Fetched 100 stories. Total story count so far: 29200\n",
            "Fetched 100 stories. Total story count so far: 29300\n",
            "Fetched 100 stories. Total story count so far: 29400\n",
            "Fetched 100 stories. Total story count so far: 29500\n",
            "Fetched 100 stories. Total story count so far: 29600\n",
            "Fetched 100 stories. Total story count so far: 29700\n",
            "Fetched 100 stories. Total story count so far: 29800\n",
            "Fetched 100 stories. Total story count so far: 29900\n",
            "Fetched 100 stories. Total story count so far: 30000\n",
            "Fetched 100 stories. Total story count so far: 30100\n",
            "Fetched 100 stories. Total story count so far: 30200\n",
            "Fetched 100 stories. Total story count so far: 30300\n",
            "Fetched 100 stories. Total story count so far: 30400\n",
            "Fetched 100 stories. Total story count so far: 30500\n",
            "Fetched 100 stories. Total story count so far: 30600\n",
            "Fetched 100 stories. Total story count so far: 30700\n",
            "Fetched 100 stories. Total story count so far: 30800\n",
            "Fetched 100 stories. Total story count so far: 30900\n",
            "Fetched 100 stories. Total story count so far: 31000\n",
            "Fetched 100 stories. Total story count so far: 31100\n",
            "Fetched 100 stories. Total story count so far: 31200\n",
            "Fetched 100 stories. Total story count so far: 31300\n",
            "Fetched 100 stories. Total story count so far: 31400\n",
            "Fetched 100 stories. Total story count so far: 31500\n",
            "Fetched 100 stories. Total story count so far: 31600\n",
            "Fetched 100 stories. Total story count so far: 31700\n",
            "Fetched 100 stories. Total story count so far: 31800\n",
            "Fetched 100 stories. Total story count so far: 31900\n",
            "Fetched 100 stories. Total story count so far: 32000\n",
            "Fetched 100 stories. Total story count so far: 32100\n",
            "Fetched 100 stories. Total story count so far: 32200\n",
            "Fetched 100 stories. Total story count so far: 32300\n",
            "Fetched 100 stories. Total story count so far: 32400\n",
            "Fetched 100 stories. Total story count so far: 32500\n",
            "Fetched 100 stories. Total story count so far: 32600\n",
            "Fetched 100 stories. Total story count so far: 32700\n",
            "Fetched 100 stories. Total story count so far: 32800\n",
            "Fetched 100 stories. Total story count so far: 32900\n",
            "Fetched 100 stories. Total story count so far: 33000\n",
            "Fetched 100 stories. Total story count so far: 33100\n",
            "Fetched 100 stories. Total story count so far: 33200\n",
            "Fetched 100 stories. Total story count so far: 33300\n",
            "Fetched 100 stories. Total story count so far: 33400\n",
            "Fetched 100 stories. Total story count so far: 33500\n",
            "Fetched 100 stories. Total story count so far: 33600\n",
            "Fetched 100 stories. Total story count so far: 33700\n",
            "Fetched 100 stories. Total story count so far: 33800\n",
            "Fetched 100 stories. Total story count so far: 33900\n",
            "Fetched 100 stories. Total story count so far: 34000\n",
            "Fetched 100 stories. Total story count so far: 34100\n",
            "Fetched 100 stories. Total story count so far: 34200\n",
            "Fetched 100 stories. Total story count so far: 34300\n",
            "Fetched 100 stories. Total story count so far: 34400\n",
            "Fetched 100 stories. Total story count so far: 34500\n",
            "Fetched 100 stories. Total story count so far: 34600\n",
            "Fetched 100 stories. Total story count so far: 34700\n",
            "Fetched 100 stories. Total story count so far: 34800\n",
            "Fetched 100 stories. Total story count so far: 34900\n",
            "Fetched 100 stories. Total story count so far: 35000\n",
            "Fetched 100 stories. Total story count so far: 35100\n",
            "Fetched 100 stories. Total story count so far: 35200\n",
            "Fetched 100 stories. Total story count so far: 35300\n",
            "Fetched 100 stories. Total story count so far: 35400\n",
            "Fetched 100 stories. Total story count so far: 35500\n",
            "Fetched 100 stories. Total story count so far: 35600\n",
            "Fetched 100 stories. Total story count so far: 35700\n",
            "Fetched 100 stories. Total story count so far: 35800\n",
            "Fetched 100 stories. Total story count so far: 35900\n",
            "Fetched 100 stories. Total story count so far: 36000\n",
            "Fetched 100 stories. Total story count so far: 36100\n",
            "Fetched 100 stories. Total story count so far: 36200\n",
            "Fetched 100 stories. Total story count so far: 36300\n",
            "Fetched 100 stories. Total story count so far: 36400\n",
            "Fetched 100 stories. Total story count so far: 36500\n",
            "Fetched 100 stories. Total story count so far: 36600\n",
            "Fetched 100 stories. Total story count so far: 36700\n",
            "Fetched 100 stories. Total story count so far: 36800\n",
            "Fetched 100 stories. Total story count so far: 36900\n",
            "Fetched 100 stories. Total story count so far: 37000\n",
            "Fetched 100 stories. Total story count so far: 37100\n",
            "Fetched 100 stories. Total story count so far: 37200\n",
            "Fetched 100 stories. Total story count so far: 37300\n",
            "Fetched 100 stories. Total story count so far: 37400\n",
            "Fetched 100 stories. Total story count so far: 37500\n",
            "Fetched 100 stories. Total story count so far: 37600\n",
            "Fetched 100 stories. Total story count so far: 37700\n",
            "Fetched 100 stories. Total story count so far: 37800\n",
            "Fetched 100 stories. Total story count so far: 37900\n",
            "Fetched 100 stories. Total story count so far: 38000\n",
            "Fetched 100 stories. Total story count so far: 38100\n",
            "Fetched 100 stories. Total story count so far: 38200\n",
            "Fetched 100 stories. Total story count so far: 38300\n",
            "Fetched 100 stories. Total story count so far: 38400\n",
            "Fetched 100 stories. Total story count so far: 38500\n",
            "Fetched 100 stories. Total story count so far: 38600\n",
            "Fetched 100 stories. Total story count so far: 38700\n",
            "Fetched 100 stories. Total story count so far: 38800\n",
            "Fetched 100 stories. Total story count so far: 38900\n",
            "Fetched 100 stories. Total story count so far: 39000\n",
            "Fetched 100 stories. Total story count so far: 39100\n",
            "Fetched 100 stories. Total story count so far: 39200\n",
            "Fetched 100 stories. Total story count so far: 39300\n",
            "Fetched 100 stories. Total story count so far: 39400\n",
            "Fetched 100 stories. Total story count so far: 39500\n",
            "Fetched 100 stories. Total story count so far: 39600\n",
            "Fetched 100 stories. Total story count so far: 39700\n",
            "Fetched 100 stories. Total story count so far: 39800\n",
            "Fetched 100 stories. Total story count so far: 39900\n",
            "Fetched 100 stories. Total story count so far: 40000\n",
            "Fetched 100 stories. Total story count so far: 40100\n",
            "Fetched 100 stories. Total story count so far: 40200\n",
            "Fetched 100 stories. Total story count so far: 40300\n",
            "Fetched 100 stories. Total story count so far: 40400\n",
            "Fetched 100 stories. Total story count so far: 40500\n",
            "Fetched 100 stories. Total story count so far: 40600\n",
            "Fetched 100 stories. Total story count so far: 40700\n",
            "Fetched 100 stories. Total story count so far: 40800\n",
            "Fetched 100 stories. Total story count so far: 40900\n",
            "Fetched 100 stories. Total story count so far: 41000\n",
            "Fetched 100 stories. Total story count so far: 41100\n",
            "Fetched 100 stories. Total story count so far: 41200\n",
            "Fetched 100 stories. Total story count so far: 41300\n",
            "Fetched 100 stories. Total story count so far: 41400\n",
            "Fetched 100 stories. Total story count so far: 41500\n",
            "Fetched 100 stories. Total story count so far: 41600\n",
            "Fetched 100 stories. Total story count so far: 41700\n",
            "Fetched 100 stories. Total story count so far: 41800\n",
            "Fetched 100 stories. Total story count so far: 41900\n",
            "Fetched 100 stories. Total story count so far: 42000\n",
            "Fetched 100 stories. Total story count so far: 42100\n",
            "Fetched 100 stories. Total story count so far: 42200\n",
            "Fetched 100 stories. Total story count so far: 42300\n",
            "Fetched 100 stories. Total story count so far: 42400\n",
            "Fetched 100 stories. Total story count so far: 42500\n",
            "Fetched 100 stories. Total story count so far: 42600\n",
            "Fetched 100 stories. Total story count so far: 42700\n",
            "Fetched 100 stories. Total story count so far: 42800\n",
            "Fetched 100 stories. Total story count so far: 42900\n",
            "Fetched 100 stories. Total story count so far: 43000\n",
            "Fetched 100 stories. Total story count so far: 43100\n",
            "Fetched 100 stories. Total story count so far: 43200\n",
            "Fetched 100 stories. Total story count so far: 43300\n",
            "Fetched 100 stories. Total story count so far: 43400\n",
            "Fetched 100 stories. Total story count so far: 43500\n",
            "Fetched 100 stories. Total story count so far: 43600\n",
            "Fetched 100 stories. Total story count so far: 43700\n",
            "Fetched 100 stories. Total story count so far: 43800\n",
            "Fetched 100 stories. Total story count so far: 43900\n",
            "Fetched 100 stories. Total story count so far: 44000\n",
            "Fetched 100 stories. Total story count so far: 44100\n",
            "Fetched 100 stories. Total story count so far: 44200\n",
            "Fetched 100 stories. Total story count so far: 44300\n",
            "Fetched 100 stories. Total story count so far: 44400\n",
            "Fetched 100 stories. Total story count so far: 44500\n",
            "Fetched 100 stories. Total story count so far: 44600\n",
            "Fetched 100 stories. Total story count so far: 44700\n",
            "Fetched 100 stories. Total story count so far: 44800\n",
            "Fetched 100 stories. Total story count so far: 44900\n",
            "Fetched 100 stories. Total story count so far: 45000\n",
            "Fetched 100 stories. Total story count so far: 45100\n",
            "Fetched 100 stories. Total story count so far: 45200\n",
            "Fetched 100 stories. Total story count so far: 45300\n",
            "Fetched 100 stories. Total story count so far: 45400\n",
            "Fetched 100 stories. Total story count so far: 45500\n",
            "Fetched 100 stories. Total story count so far: 45600\n",
            "Fetched 100 stories. Total story count so far: 45700\n",
            "Fetched 100 stories. Total story count so far: 45800\n",
            "Fetched 100 stories. Total story count so far: 45900\n",
            "Fetched 100 stories. Total story count so far: 46000\n",
            "Fetched 100 stories. Total story count so far: 46100\n",
            "Fetched 100 stories. Total story count so far: 46200\n",
            "Fetched 100 stories. Total story count so far: 46300\n",
            "Fetched 100 stories. Total story count so far: 46400\n",
            "Fetched 100 stories. Total story count so far: 46500\n",
            "Fetched 100 stories. Total story count so far: 46600\n",
            "Fetched 100 stories. Total story count so far: 46700\n",
            "Fetched 100 stories. Total story count so far: 46800\n",
            "Fetched 100 stories. Total story count so far: 46900\n",
            "Fetched 100 stories. Total story count so far: 47000\n",
            "Fetched 100 stories. Total story count so far: 47100\n",
            "Fetched 100 stories. Total story count so far: 47200\n",
            "Fetched 100 stories. Total story count so far: 47300\n",
            "Fetched 100 stories. Total story count so far: 47400\n",
            "Fetched 100 stories. Total story count so far: 47500\n",
            "Fetched 100 stories. Total story count so far: 47600\n",
            "Fetched 100 stories. Total story count so far: 47700\n",
            "Fetched 100 stories. Total story count so far: 47800\n",
            "Fetched 100 stories. Total story count so far: 47900\n",
            "Fetched 100 stories. Total story count so far: 48000\n",
            "Fetched 100 stories. Total story count so far: 48100\n",
            "Fetched 100 stories. Total story count so far: 48200\n",
            "Fetched 100 stories. Total story count so far: 48300\n",
            "Fetched 100 stories. Total story count so far: 48400\n",
            "Fetched 100 stories. Total story count so far: 48500\n",
            "Fetched 100 stories. Total story count so far: 48600\n",
            "Fetched 100 stories. Total story count so far: 48700\n",
            "Fetched 100 stories. Total story count so far: 48800\n",
            "Fetched 100 stories. Total story count so far: 48900\n",
            "Fetched 100 stories. Total story count so far: 49000\n",
            "Fetched 100 stories. Total story count so far: 49100\n",
            "Fetched 100 stories. Total story count so far: 49200\n",
            "Fetched 100 stories. Total story count so far: 49300\n",
            "Fetched 100 stories. Total story count so far: 49400\n",
            "Fetched 100 stories. Total story count so far: 49500\n",
            "Fetched 100 stories. Total story count so far: 49600\n",
            "Fetched 100 stories. Total story count so far: 49700\n",
            "Fetched 100 stories. Total story count so far: 49800\n",
            "Fetched 100 stories. Total story count so far: 49900\n",
            "Fetched 100 stories. Total story count so far: 50000\n",
            "Fetched 100 stories. Total story count so far: 50100\n",
            "Fetched 100 stories. Total story count so far: 50200\n",
            "Fetched 100 stories. Total story count so far: 50300\n",
            "Fetched 100 stories. Total story count so far: 50400\n",
            "Fetched 100 stories. Total story count so far: 50500\n",
            "Fetched 100 stories. Total story count so far: 50600\n",
            "Fetched 100 stories. Total story count so far: 50700\n",
            "Fetched 100 stories. Total story count so far: 50800\n",
            "Fetched 100 stories. Total story count so far: 50900\n",
            "Fetched 100 stories. Total story count so far: 51000\n",
            "Fetched 100 stories. Total story count so far: 51100\n",
            "Fetched 100 stories. Total story count so far: 51200\n",
            "Fetched 100 stories. Total story count so far: 51300\n",
            "Fetched 100 stories. Total story count so far: 51400\n",
            "Fetched 100 stories. Total story count so far: 51500\n",
            "Fetched 100 stories. Total story count so far: 51600\n",
            "Fetched 100 stories. Total story count so far: 51700\n",
            "Fetched 100 stories. Total story count so far: 51800\n",
            "Fetched 100 stories. Total story count so far: 51900\n",
            "Fetched 100 stories. Total story count so far: 52000\n",
            "Fetched 100 stories. Total story count so far: 52100\n",
            "Fetched 100 stories. Total story count so far: 52200\n",
            "Fetched 100 stories. Total story count so far: 52300\n",
            "Fetched 100 stories. Total story count so far: 52400\n",
            "Fetched 100 stories. Total story count so far: 52500\n",
            "Fetched 100 stories. Total story count so far: 52600\n",
            "Fetched 100 stories. Total story count so far: 52700\n",
            "Fetched 100 stories. Total story count so far: 52800\n",
            "Fetched 100 stories. Total story count so far: 52900\n",
            "Fetched 100 stories. Total story count so far: 53000\n",
            "Fetched 100 stories. Total story count so far: 53100\n",
            "Fetched 100 stories. Total story count so far: 53200\n",
            "Fetched 100 stories. Total story count so far: 53300\n",
            "Fetched 100 stories. Total story count so far: 53400\n",
            "Fetched 100 stories. Total story count so far: 53500\n",
            "Fetched 100 stories. Total story count so far: 53600\n",
            "Fetched 100 stories. Total story count so far: 53700\n",
            "Fetched 100 stories. Total story count so far: 53800\n",
            "Fetched 100 stories. Total story count so far: 53900\n",
            "Fetched 100 stories. Total story count so far: 54000\n",
            "Fetched 100 stories. Total story count so far: 54100\n",
            "Fetched 100 stories. Total story count so far: 54200\n",
            "Fetched 100 stories. Total story count so far: 54300\n",
            "Fetched 100 stories. Total story count so far: 54400\n",
            "Fetched 100 stories. Total story count so far: 54500\n",
            "Fetched 100 stories. Total story count so far: 54600\n",
            "Fetched 100 stories. Total story count so far: 54700\n",
            "Fetched 100 stories. Total story count so far: 54800\n",
            "Fetched 100 stories. Total story count so far: 54900\n",
            "Fetched 100 stories. Total story count so far: 55000\n",
            "Fetched 100 stories. Total story count so far: 55100\n",
            "Fetched 100 stories. Total story count so far: 55200\n",
            "Fetched 100 stories. Total story count so far: 55300\n",
            "Fetched 100 stories. Total story count so far: 55400\n",
            "Fetched 100 stories. Total story count so far: 55500\n",
            "Fetched 100 stories. Total story count so far: 55600\n",
            "Fetched 100 stories. Total story count so far: 55700\n",
            "Fetched 100 stories. Total story count so far: 55800\n",
            "Fetched 100 stories. Total story count so far: 55900\n",
            "Fetched 100 stories. Total story count so far: 56000\n",
            "Fetched 100 stories. Total story count so far: 56100\n",
            "Fetched 100 stories. Total story count so far: 56200\n",
            "Fetched 100 stories. Total story count so far: 56300\n",
            "Fetched 100 stories. Total story count so far: 56400\n",
            "Fetched 100 stories. Total story count so far: 56500\n",
            "Fetched 100 stories. Total story count so far: 56600\n",
            "Fetched 100 stories. Total story count so far: 56700\n",
            "Fetched 100 stories. Total story count so far: 56800\n",
            "Fetched 100 stories. Total story count so far: 56900\n",
            "Fetched 100 stories. Total story count so far: 57000\n",
            "Fetched 100 stories. Total story count so far: 57100\n",
            "Fetched 100 stories. Total story count so far: 57200\n",
            "Fetched 100 stories. Total story count so far: 57300\n",
            "Fetched 100 stories. Total story count so far: 57400\n",
            "Fetched 100 stories. Total story count so far: 57500\n",
            "Fetched 100 stories. Total story count so far: 57600\n",
            "Fetched 100 stories. Total story count so far: 57700\n",
            "Fetched 100 stories. Total story count so far: 57800\n",
            "Fetched 100 stories. Total story count so far: 57900\n",
            "Fetched 100 stories. Total story count so far: 58000\n",
            "Fetched 100 stories. Total story count so far: 58100\n",
            "Fetched 100 stories. Total story count so far: 58200\n",
            "Fetched 100 stories. Total story count so far: 58300\n",
            "Fetched 100 stories. Total story count so far: 58400\n",
            "Fetched 100 stories. Total story count so far: 58500\n",
            "Fetched 100 stories. Total story count so far: 58600\n",
            "Fetched 100 stories. Total story count so far: 58700\n",
            "Fetched 100 stories. Total story count so far: 58800\n",
            "Fetched 100 stories. Total story count so far: 58900\n",
            "Fetched 100 stories. Total story count so far: 59000\n",
            "Fetched 100 stories. Total story count so far: 59100\n",
            "Fetched 100 stories. Total story count so far: 59200\n",
            "Fetched 100 stories. Total story count so far: 59300\n",
            "Fetched 100 stories. Total story count so far: 59400\n",
            "Fetched 100 stories. Total story count so far: 59500\n",
            "Fetched 100 stories. Total story count so far: 59600\n",
            "Fetched 100 stories. Total story count so far: 59700\n",
            "Fetched 100 stories. Total story count so far: 59800\n",
            "Fetched 100 stories. Total story count so far: 59900\n",
            "Fetched 100 stories. Total story count so far: 60000\n",
            "27\n",
            "************\n",
            "Fetched 60000 stories mentioning 'corona' in the title, are in English, and were published between NOW-3MONTHS and NOW\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou1a8W01chzQ",
        "colab_type": "code",
        "outputId": "34d17235-424b-4994-e03f-d23eb2e61d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "#Corpus as docs for vectorization\n",
        "corpus=''\n",
        "for de in data:\n",
        "  #NOTE in case there was no EN news from the country -> solve it by increasing the news request in the api call\n",
        "  if(len(data[de])>0):\n",
        "    corpus = de\n",
        "    \n",
        "    for s in data[de][0]:\n",
        "        corpus = corpus+\" \"+s\n",
        "for d in data:\n",
        "  if(len(data[d])>0):\n",
        "    print(d)\n",
        "    print(data[d][0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Belgium\n",
            "['corona', 'virus', 'cat', 'corona virus', 'foreign media', 'veterinary surgeons', 'Content', 'media', 'foreign', 'requirement', 'infected', 'veterinary', 'article', 'surgeons', 'respect', 'contact', 'query', 'News', 'Hiru', 'permission', 'Hong Kong', 'feline', 'infection', 'Sri Lanka', 'public health']\n",
            "Latvia\n",
            "new\n",
            "Netherlands\n",
            "['Covid-19', 'optimism', 'assoc.', 'figures', 'early', 'intensive care', 'coronavirus patients', 'patients', 'care', 'intensive', 'people', 'ICUs', 'total', 'coronavirus', 'Gommers', 'Sunday', 'number', 'a.m.', 'outflow', 'satisfied', 'inflow', 'Monday', 'NICE', 'pandemic']\n",
            "Spain\n",
            "['Corona', 'Actor', 'Virus', 'American', 'Content', 'number', 'actor', 'requirement', 'article', 'Hanks', 'Renowned', 'respect', 'query', 'News', 'contact', 'wife', 'Hiru', 'permission', 'March', 'deaths', 'Editor', 'Rita', 'virus', 'France', 'Tom Hanks', 'Rita Wilson', 'India', 'Sri Lanka']\n",
            "Italy\n",
            "['Corona', 'virus', 'northern', 'family', 'Iraqi', 'Iraqi Embassy', 'Embassy', 'infected', 'statement', 'stable', 'Rome', 'people', 'health', 'NINA', 'Baghdad']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7HgEQPtYUxF3",
        "outputId": "79f45b2c-4bd9-483e-e5c9-7f3d4950b2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "#kmeans again\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vocabulary = \"icu beds capacity hopsitalized\".split()\n",
        "vocabulary.append('intensive care unit')\n",
        "vocabulary.append('infected people')\n",
        "\n",
        "\n",
        "documents = [\"This little kitty came to play when I was eating at a restaurant.\",\n",
        "             \"Merley has the best squooshy kitten belly.\",\n",
        "             \"Google Translate app is incredible.\",\n",
        "             \"If you open 100 tab in google you get a smiley face.\",\n",
        "             \"Best cat photo I've ever taken.\",\n",
        "             \"Climbing ninja cat.\",\n",
        "             \"Impressed with google map feedback.\",\n",
        "             \"Key promoter extension for Google Chrome.\"]\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', vocabulary=vocabulary)\n",
        "X = vectorizer.fit_transform(data)\n",
        "print(vectorizer.get_stop_words)\n",
        "true_k = 2\n",
        "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
        "model.fit(X)\n",
        "\n",
        "print(\"Top terms per cluster:\")\n",
        "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = vectorizer.get_feature_names()\n",
        "for i in range(true_k):\n",
        "    print(\"Cluster %d:\" % i),\n",
        "    for ind in order_centroids[i, :10]:\n",
        "        print(' %s' % terms[ind]),\n",
        "    print\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction\")\n",
        "\n",
        "Y = vectorizer.transform(['Italy' 'infected' 'Majority', 'patients' 'country' 'virus' 'Agra'\n",
        " 'Corona' 'infected people' 'samples (infection' 'people' 'corona'\n",
        " 'Health' 'city' 'Government' 'samples' 'International' 'China' 'Content'\n",
        " 'health services' 'Delhi' 'infection' 'department' 'India' 'Hindustan'\n",
        " 'lakh' 'Taj Mahal' 'Chinese' 'World Health Organization'\n",
        " 'district hospital' 'hospital' 'camping' 'international standard'\n",
        " 'corona virus' 'wards'])\n",
        "prediction = model.predict(Y)\n",
        "print(prediction)\n",
        "\n",
        "\n",
        "Y = vectorizer.transform(['Netherlands' 'patients' 'Covid-19' 'Covid-19 patients' 'Care (NVIC'\n",
        " 'Gommers' 'health' 'Dutch' 'system' 'Care' 'summer' 'NVIC' 'percent'\n",
        " 'letter' 'capacity' 'assumptions' 'report' 'joint' 'years' 'public'\n",
        " 'healthcare' 'vaccine' 'acute care' 'intensive care unit' 'public health'])\n",
        "prediction = model.predict(Y)\n",
        "print(prediction)\n",
        " "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method _VectorizerMixin.get_stop_words of TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
            "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
            "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
            "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
            "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, use_idf=True,\n",
            "                vocabulary=['icu', 'beds', 'capacity', 'hopsitalized',\n",
            "                            'intensive care unit', 'infected people'])>\n",
            "Top terms per cluster:\n",
            "Cluster 0:\n",
            " infected people\n",
            " intensive care unit\n",
            " hopsitalized\n",
            " capacity\n",
            " beds\n",
            " icu\n",
            "Cluster 1:\n",
            " infected people\n",
            " intensive care unit\n",
            " hopsitalized\n",
            " capacity\n",
            " beds\n",
            " icu\n",
            "\n",
            "\n",
            "Prediction\n",
            "[0 0]\n",
            "[0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-GE63aXEELq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#spectral co clustering\n",
        "from collections import defaultdict\n",
        "import operator\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.cluster import SpectralCoclustering\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.cluster import v_measure_score\n",
        "\n",
        "print(__doc__)\n",
        "\n",
        "\n",
        "def number_normalizer(tokens):\n",
        "    \"\"\" Map all numeric tokens to a placeholder.\n",
        "\n",
        "    For many applications, tokens that begin with a number are not directly\n",
        "    useful, but the fact that such a token exists can be relevant.  By applying\n",
        "    this form of dimensionality reduction, some methods may perform better.\n",
        "    \"\"\"\n",
        "    return (\"#NUMBER\" if token[0].isdigit() else token for token in tokens)\n",
        "\n",
        "\n",
        "class NumberNormalizingVectorizer(TfidfVectorizer):\n",
        "    def build_tokenizer(self):\n",
        "        tokenize = super().build_tokenizer()\n",
        "        return lambda doc: list(number_normalizer(tokenize(doc)))\n",
        "\n",
        "\n",
        "# exclude 'comp.os.ms-windows.misc'\n",
        "categories = ['alt.atheism', 'comp.graphics',\n",
        "              'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
        "              'comp.windows.x', 'misc.forsale', 'rec.autos',\n",
        "              'rec.motorcycles', 'rec.sport.baseball',\n",
        "              'rec.sport.hockey', 'sci.crypt', 'sci.electronics',\n",
        "              'sci.med', 'sci.space', 'soc.religion.christian',\n",
        "              'talk.politics.guns', 'talk.politics.mideast',\n",
        "              'talk.politics.misc', 'talk.religion.misc']\n",
        "newsgroups = fetch_20newsgroups(categories=categories)\n",
        "news_corona_cat = \"icu beds infection hospital \"\n",
        "print(newsgroups)\n",
        "#y_true = newsgroups.target\n",
        "\n",
        "vectorizer = NumberNormalizingVectorizer(stop_words='english', min_df=3)\n",
        "cocluster = SpectralCoclustering(n_clusters=2,\n",
        "                                 svd_method='arpack', random_state=0)\n",
        "kmeans = MiniBatchKMeans(n_clusters=2, batch_size=20000,\n",
        "                         random_state=0)\n",
        "\n",
        "print(\"Vectorizing...\")\n",
        "X = vectorizer.fit_transform(corpus.split())\n",
        "\n",
        "print(\"Coclustering...\")\n",
        "start_time = time()\n",
        "cocluster.fit(X)\n",
        "y_cocluster = cocluster.row_labels_\n",
        "\n",
        "\n",
        "print(\"MiniBatchKMeans...\")\n",
        "start_time = time()\n",
        "y_kmeans = kmeans.fit_predict(X)\n",
        "\n",
        "\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "#document_names = list(newsgroups.target_names[i] for i in newsgroups.target)\n",
        "\n",
        "\n",
        "def bicluster_ncut(i):\n",
        "    rows, cols = cocluster.get_indices(i)\n",
        "    if not (np.any(rows) and np.any(cols)):\n",
        "        import sys\n",
        "        return sys.float_info.max\n",
        "    row_complement = np.nonzero(np.logical_not(cocluster.rows_[i]))[0]\n",
        "    col_complement = np.nonzero(np.logical_not(cocluster.columns_[i]))[0]\n",
        "    # Note: the following is identical to X[rows[:, np.newaxis],\n",
        "    # cols].sum() but much faster in scipy <= 0.16\n",
        "    weight = X[rows][:, cols].sum()\n",
        "    cut = (X[row_complement][:, cols].sum() +\n",
        "           X[rows][:, col_complement].sum())\n",
        "    return cut / weight\n",
        "\n",
        "\n",
        "def most_common(d):\n",
        "    \"\"\"Items of a defaultdict(int) with the highest values.\n",
        "\n",
        "    Like Counter.most_common in Python >=2.7.\n",
        "    \"\"\"\n",
        "    return sorted(d.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "\n",
        "bicluster_ncuts = list(bicluster_ncut(i)\n",
        "                       for i in range(len(newsgroups.target_names)))\n",
        "best_idx = np.argsort(bicluster_ncuts)[:5]\n",
        "\n",
        "print()\n",
        "print(\"Best biclusters:\")\n",
        "print(\"----------------\")\n",
        "for idx, cluster in enumerate(best_idx):\n",
        "    n_rows, n_cols = cocluster.get_shape(cluster)\n",
        "    cluster_docs, cluster_words = cocluster.get_indices(cluster)\n",
        "    if not len(cluster_docs) or not len(cluster_words):\n",
        "        continue\n",
        "\n",
        "    # categories\n",
        "    counter = defaultdict(int)\n",
        "    for i in cluster_docs:\n",
        "        counter[document_names[i]] += 1\n",
        "    cat_string = \", \".join(\"{:.0f}% {}\".format(float(c) / n_rows * 100, name)\n",
        "                           for name, c in most_common(counter)[:3])\n",
        "\n",
        "    # words\n",
        "    out_of_cluster_docs = cocluster.row_labels_ != cluster\n",
        "    out_of_cluster_docs = np.where(out_of_cluster_docs)[0]\n",
        "    word_col = X[:, cluster_words]\n",
        "    word_scores = np.array(word_col[cluster_docs, :].sum(axis=0) -\n",
        "                           word_col[out_of_cluster_docs, :].sum(axis=0))\n",
        "    word_scores = word_scores.ravel()\n",
        "    important_words = list(feature_names[cluster_words[i]]\n",
        "                           for i in word_scores.argsort()[:-11:-1])\n",
        "\n",
        "    print(\"bicluster {} : {} documents, {} words\".format(\n",
        "        idx, n_rows, n_cols))\n",
        "    print(\"categories   : {}\".format(cat_string))\n",
        "    print(\"words        : {}\\n\".format(', '.join(important_words)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTOjIQvgL55e",
        "colab_type": "code",
        "outputId": "6c4ec2cb-bd28-49a3-c4f6-e49c3da9c19e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "pip install hdbscan"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hdbscan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/2f/2423d844072f007a74214c1adc46260e45f034bb1679ccadfbb8a601f647/hdbscan-0.8.26.tar.gz (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 8.0MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.14.1)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.18.3)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.29.17)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.4.1)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.26-cp36-cp36m-linux_x86_64.whl size=2358787 sha256=63948b58f48045ec602f8f4446fe8b977c69062a9d2fedf64969db1b9caa7042\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/38/41/372f034d8abd271ef7787a681e0a47fc05d472683a7eb088ed\n",
            "Successfully built hdbscan\n",
            "Installing collected packages: hdbscan\n",
            "Successfully installed hdbscan-0.8.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROb81uUafdpf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85c356fc-1e83-4ac7-b0a1-107cb2015c73"
      },
      "source": [
        "print(len(full_text))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-k0YgvsM02Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "corpus_train = full_text[:5086]\n",
        "corpus_test = full_text[-1272:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcCs73jWGehQ",
        "colab_type": "code",
        "outputId": "7e46319e-00e0-4798-992c-aa898c816739",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "import hdbscan\n",
        "#CURRENT\n",
        "\n",
        "vocabulary = \"icu beds capacity hospitalized\".split()\n",
        "vocabulary.append('intensive care unit')\n",
        "true_test_labels = ['infection focused','icu focused']\n",
        "vocabulary2 = \"icu beds capacity\".split()\n",
        "\n",
        "vectorizer = TfidfVectorizer(use_idf=True,min_df=0.4,stop_words='english')#,vocabulary=vocabulary2)\n",
        "X = vectorizer.fit_transform(corpus_train)\n",
        " \n",
        "\n",
        "    \n",
        "true_k=2\n",
        "model = KMeans(init='k-means++', n_clusters=true_k, max_iter=100, n_init=2)\n",
        "model.fit(X)\n",
        "\n",
        "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = vectorizer.get_feature_names()\n",
        "\n",
        "for i in range(true_k):\n",
        "    print(\"Cluster %d:\" % i),\n",
        "    for ind in order_centroids[i, :10]:\n",
        "        print(' %s' % terms[ind]),\n",
        "    print\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction\")\n",
        "\n",
        "output_pred = []\n",
        "for text in corpus_test:\n",
        "  X = vectorizer.transform(text.split())\n",
        "  true_test_labels = ['infection focused','icu focused']\n",
        "  predicted_labels_kmeans = model.predict(X)\n",
        "\n",
        "  country = list(set(text.split()).intersection(eu))[0]\n",
        "  all_pred_countries = np.append(all_pred_countries,country)\n",
        "\n",
        "  focus = true_test_labels[np.int(predicted_labels_kmeans[0])]\n",
        "  c_f = (country,focus)\n",
        "  output_pred.append(c_f)\n",
        "  \n",
        "#print(output_pred[:3])\n",
        "pred_focus = []\n",
        "pred_country = list(set(all_pred_countries))\n",
        "for country_name in pred_country:\n",
        "  set_to_count = [focus for (country, focus) in output_pred if country in country_name]\n",
        "  country_infection = set_to_count.count('infection focused')\n",
        "  country_icu = set_to_count.count('icu focused')\n",
        "  if country_infection > country_icu:\n",
        "    pred_focus.append((country_name, 'infection focused'))\n",
        "  else:\n",
        "    pred_focus.append((country_name, 'icu focused'))\n",
        "#for ct in pred_country:\n",
        "x\n",
        "print(pred_focus)\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster 0:\n",
            " virus\n",
            " coronavirus\n",
            "Cluster 1:\n",
            " coronavirus\n",
            " virus\n",
            "\n",
            "\n",
            "Prediction\n",
            "[('Greece', 'infection focused'), ('Poland', 'infection focused'), ('Ireland', 'infection focused'), ('Portugal', 'infection focused'), ('Cyprus', 'infection focused'), ('Germany', 'infection focused'), ('Latvia', 'infection focused'), ('Slovakia', 'infection focused'), ('Spain', 'infection focused'), ('Denmark', 'infection focused'), ('Hungary', 'infection focused'), ('Czechia', 'infection focused'), ('Austria', 'infection focused'), ('Netherlands', 'infection focused'), ('Estonia', 'infection focused'), ('Italy', 'infection focused'), ('Luxembourg', 'infection focused'), ('Slovenia', 'infection focused'), ('Bulgaria', 'infection focused'), ('Romania', 'infection focused'), ('Malta', 'infection focused'), ('Croatia', 'infection focused'), ('Belgium', 'infection focused'), ('France', 'infection focused'), ('Finland', 'infection focused'), ('Lithuania', 'infection focused'), ('Sweden', 'infection focused')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12R0vgt0Hh-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjw9AitjHe9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MbFfXApHauu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLevZpNXGkK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_xE8NB0GfTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRnWM5-PFvXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEAxq_PMFgdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms_87XVDEtqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "import hdbscan\n",
        "#CURRENT\n",
        "\n",
        "vocabulary = \"icu beds capacity hospitalized\".split()\n",
        "vocabulary.append('intensive care unit')\n",
        "true_test_labels = ['infection focused','icu focused']\n",
        "vocabulary2 = \"icu beds capacity\".split()\n",
        "\n",
        "vectorizer = TfidfVectorizer(use_idf=True,min_df=0.4,stop_words='english')#,vocabulary=vocabulary2)\n",
        "X = vectorizer.fit_transform(corpus_train)\n",
        " \n",
        "\n",
        "    \n",
        "true_k=2\n",
        "model = KMeans(init='k-means++', n_clusters=true_k, max_iter=100, n_init=2)\n",
        "model.fit(X)\n",
        "\n",
        "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = vectorizer.get_feature_names()\n",
        "\n",
        "for i in range(true_k):\n",
        "    print(\"Cluster %d:\" % i),\n",
        "    for ind in order_centroids[i, :10]:\n",
        "        print(' %s' % terms[ind]),\n",
        "    print\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Prediction\")\n",
        "\n",
        "#df = pd.DataFrame(columns=['country', 'infection_focused', 'icu_focused'])\n",
        "all_pred_countries=[]\n",
        "for text in corpus_test:\n",
        "  X = vectorizer.transform(text.split())\n",
        "  true_test_labels = ['infection focused','icu focused']\n",
        "  predicted_labels_kmeans = model.predict(X)\n",
        "\n",
        "  country = list(set(text.split()).intersection(eu))[0]\n",
        "  all_pred_countries = np.append(all_pred_countries,country)\n",
        "  focus = true_test_labels[np.int(predicted_labels_kmeans[0])]\n",
        "  result = np.append(country,focus)\n",
        "\n",
        "\n",
        "#print(all_pred_countries)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3od7cg7BasC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}